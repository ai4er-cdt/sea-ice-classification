{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For the data loader\n",
    "import os\n",
    "#import cv2\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "# For data augmentation\n",
    "from torchvision import transforms\n",
    "\n",
    "# For creating the model\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import segmentation_models_pytorch as smp\n",
    "\n",
    "# For training the model\n",
    "import numpy as np\n",
    "\n",
    "# For tracking the model\n",
    "import wandb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 1: Load the data (dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The SeaIceData class contains functions for loading the data and creating a custom dataset\n",
    "class SeaIceDataset(Dataset):\n",
    "    def __init__(self, sar_path: str, chart_path: str, transform=None, augmentation=None):\n",
    "        self.sar_path = sar_path\n",
    "        self.sar_files = os.listdir(self.sar_path)\n",
    "        self.chart_path = chart_path\n",
    "        self.chart_files = os.listdir(self.chart_path)\n",
    "        self.transform = transform\n",
    "        ### apply augmentation at the data loader stage or later stage (for training data only?) ###\n",
    "        # self.augmentation = augmentation\n",
    "        # self.train_dataloader =  train_dataloader\n",
    "\n",
    "# Fetch the data\n",
    "    def __getitem__(self, index):\n",
    "        sar_img = os.path.join(self.sar_path, self.sar_files[index])\n",
    "        chart_img = os.path.join(self.chart_path, self.chart_files[index]) \n",
    "\n",
    "        ### Could/should we use cv2 or io for reading the data?\n",
    "        \n",
    "        sar = io.imread(sar_img).copy()  # take all bands for shape of 256 x 256 x 3\n",
    "        chart = io.imread(chart_img).copy()[:, :, 0]  # take red band only for shape of 256 x 256 x 1\n",
    "        chart[chart < 80] = 0  # binarise to water\n",
    "        chart[chart >= 80] = 255  # binarise to ice\n",
    "        sample = {\"sar\": sar, \"chart\": chart}\n",
    "\n",
    "        if self.transform:\n",
    "            sample = {\"sar\": self.transform(sar), \"chart\": self.transform(chart).squeeze(0).long()}\n",
    "        return sample\n",
    "\n",
    "        ### TBC if needed at this stage ###\n",
    "        #if self.augmentation:\n",
    "            #sample = {\"sar\": self.augmentation(sar), \"chart\": self.augmentation(chart)}\n",
    "\n",
    "# Keep going through all data    \n",
    "    def __len__(self):\n",
    "        return len(self.sar_files)\n",
    "\n",
    "### TBC if needed at this stage - Transformations/augmentation for training data only ###\n",
    "#train_transform = transforms.Compose([\n",
    "#    transforms.RandomHorizontalFlip(),\n",
    "#    transforms.RandomRotation(30)\n",
    "#])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 2: Data Augmentation\n",
    "\n",
    "See: https://github.com/qubvel/segmentation_models.pytorch/blob/master/examples/cars%20segmentation%20(camvid).ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 3: Split dataset into training/testing/validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split the data into training and validation sets\n",
    "train_data = SARData(sar_dir, chart_dir, train_transform, train=True)\n",
    "val_data = SARData(sar_dir, chart_dir, val_transform, train=False)\n",
    "\n",
    "# create dataloaders for the training and validation sets\n",
    "train_dataloader = DataLoader(train_data, batch_size=16, shuffle=True)\n",
    "val_dataloader = DataLoader(val_data, batch_size=16, shuffle=False)\n",
    "\n",
    "### Example from Andrew\n",
    "train_dataset = SeaIceDataset(sar_path=\"./sar\", chart_path=\"./chart\", transform=transforms.ToTensor())\n",
    "train_dataloader = DataLoader(train_dataset, shuffle=True)\n",
    "val_dataset = SeaIceDataset(sar_path=\"./sar\", chart_path=\"./chart\", transform=transforms.ToTensor())\n",
    "val_dataloader = DataLoader(val_dataset, shuffle=False)\n",
    "\n",
    "### From https://github.com/qubvel/segmentation_models.pytorch/blob/master/examples/cars%20segmentation%20(camvid).ipynb\n",
    "\n",
    "train_dataset = Dataset(\n",
    "    x_train_dir, \n",
    "    y_train_dir, \n",
    "    augmentation=get_training_augmentation(), \n",
    "    preprocessing=get_preprocessing(preprocessing_fn),\n",
    "    classes=CLASSES,\n",
    ")\n",
    "\n",
    "valid_dataset = Dataset(\n",
    "    x_valid_dir, \n",
    "    y_valid_dir, \n",
    "    augmentation=get_validation_augmentation(), \n",
    "    preprocessing=get_preprocessing(preprocessing_fn),\n",
    "    classes=CLASSES,\n",
    ")\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=8, shuffle=True, num_workers=12)\n",
    "valid_loader = DataLoader(valid_dataset, batch_size=1, shuffle=False, num_workers=4)\n",
    "\n",
    "\n",
    "### EXAMPLE FROM https://github.com/MohammadBakir/Pytorch-Flower-Image-Classification/blob/master/Image%20Classifier%20Densenet201.py\n",
    "#Defining data directories, modify accordingly\n",
    "data_dir = './flower_data/flower_data'\n",
    "train_dir = data_dir + '/train'\n",
    "valid_dir = data_dir + '/valid'\n",
    "test_dir = data_dir + '/test'\n",
    "\n",
    "#Define transforms for the training and validation sets\n",
    "#Using pretrained Pytorch model trained on image sizes 224. Modify ResizedCrop and CenterCrop according to needs. \n",
    "data_transforms_train = transforms.Compose([transforms.RandomResizedCrop(256),\n",
    "                                            transforms.RandomRotation(30),\n",
    "                                            transforms.ColorJitter(),\n",
    "                                            transforms.RandomHorizontalFlip(),\n",
    "                                            transforms.CenterCrop(224), \n",
    "                                            transforms.ToTensor(),\n",
    "                                            transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])])\n",
    "\n",
    "data_transforms_validation = transforms.Compose([transforms.Resize(256),\n",
    "                                                 transforms.CenterCrop(224),\n",
    "                                                 transforms.ToTensor(),\n",
    "                                                 transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])])\n",
    "\n",
    "data_transforms_test = transforms.Compose([transforms.Resize(256),\n",
    "                                                 transforms.CenterCrop(224),\n",
    "                                                 transforms.ToTensor(),\n",
    "                                                 transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])])\n",
    "\n",
    "#Load the datasets with ImageFolder\n",
    "image_dataset_train = datasets.ImageFolder(train_dir, transform = data_transforms_train)\n",
    "\n",
    "image_dataset_validation = datasets.ImageFolder(valid_dir, transform = data_transforms_validation)\n",
    "\n",
    "image_dataset_test = datasets.ImageFolder(test_dir, transform = data_transforms_validation)\n",
    "\n",
    "\n",
    "# Using the image datasets and the trainforms, define the dataloaders\n",
    "#batch size and num workers can be modified accordingly. \n",
    "batch_size =256\n",
    "num_workers=4\n",
    " \n",
    "\n",
    "dataloader_train = torch.utils.data.DataLoader(image_dataset_train, batch_size=batch_size,\n",
    "                                               num_workers=num_workers, shuffle=True)\n",
    "\n",
    "dataloader_valid = torch.utils.data.DataLoader(image_dataset_validation, batch_size=batch_size,\n",
    "                                               num_workers=num_workers, shuffle=True)\n",
    "\n",
    "dataloader_test = torch.utils.data.DataLoader(image_dataset_test, batch_size=batch_size,\n",
    "                                               num_workers=num_workers, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 4: Create the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "__init__() got an unexpected keyword argument 'pretrained'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/Users/meghanplumridge/Desktop/CNN.ipynb Cell 8\u001b[0m in \u001b[0;36m<cell line: 10>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/meghanplumridge/Desktop/CNN.ipynb#X11sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39m### See https://pytorch.org/hub/pytorch_vision_densenet/ for info about Densenet\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/meghanplumridge/Desktop/CNN.ipynb#X11sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m \n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/meghanplumridge/Desktop/CNN.ipynb#X11sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m \u001b[39m### See https://paperswithcode.com/lib/torchvision/densenet for documentation on how to set this up!!!!\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/meghanplumridge/Desktop/CNN.ipynb#X11sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m \n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/meghanplumridge/Desktop/CNN.ipynb#X11sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m \u001b[39m# Using Densetnet201 from https://segmentation-modelspytorch.readthedocs.io/en/latest/ \u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/meghanplumridge/Desktop/CNN.ipynb#X11sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m densenet \u001b[39m=\u001b[39m smp\u001b[39m.\u001b[39;49mUnet(\u001b[39m'\u001b[39;49m\u001b[39mdensenet201\u001b[39;49m\u001b[39m'\u001b[39;49m, encoder_weights\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mimagenet\u001b[39;49m\u001b[39m'\u001b[39;49m, pretrained\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/meghanplumridge/Desktop/CNN.ipynb#X11sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m \u001b[39m### The model has been pre-trained on XXX so we need to transform our data to match\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/meghanplumridge/Desktop/CNN.ipynb#X11sZmlsZQ%3D%3D?line=15'>16</a>\u001b[0m ENCODER \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mse_resnext50_32x4d\u001b[39m\u001b[39m'\u001b[39m\n",
      "\u001b[0;31mTypeError\u001b[0m: __init__() got an unexpected keyword argument 'pretrained'"
     ]
    }
   ],
   "source": [
    "### See https://pytorch.org/hub/pytorch_vision_densenet/ for info about Densenet\n",
    "\n",
    "### See https://paperswithcode.com/lib/torchvision/densenet for documentation on how to set this up!!!!\n",
    "\n",
    "#### MOST HELPFUL SO FAR ####\n",
    "## 1. Work through this: https://github.com/shounak8/AIML_Tutotials/blob/master/Deep_Learning/PyTorch/santa_or_not/santa_pytorch_pretrained_model.ipynb \n",
    "## 2. Then this: https://www.kaggle.com/code/balraj98/unet-with-pretrained-resnet50-encoder-pytorch\n",
    "## 3. Ot this: https://github.com/MohammadBakir/Pytorch-Flower-Image-Classification/blob/master/Image%20Classifier%20Densenet201.py \n",
    "\n",
    "# Using Densetnet201 from https://segmentation-modelspytorch.readthedocs.io/en/latest/ \n",
    "densenet = smp.Unet('densenet201', encoder_weights='imagenet', pretrained=True)\n",
    "\n",
    "### The model has been pre-trained on XXX so we need to transform our data to match\n",
    "\n",
    "### Densenet expects 256 size?\n",
    "\n",
    "\n",
    "\n",
    "ENCODER = 'se_resnext50_32x4d'\n",
    "ENCODER_WEIGHTS = 'imagenet'\n",
    "CLASSES = ['car']\n",
    "ACTIVATION = 'sigmoid' # could be None for logits or 'softmax2d' for multiclass segmentation\n",
    "DEVICE = 'cuda'\n",
    "\n",
    "# create segmentation model with pretrained encoder\n",
    "model = smp.FPN(\n",
    "    encoder_name=ENCODER, \n",
    "    encoder_weights=ENCODER_WEIGHTS, \n",
    "    classes=len(CLASSES), \n",
    "    activation=ACTIVATION,\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "# create a custom classifier using the densenet201 encoder\n",
    "class Densenet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Densenet, self).__init__()\n",
    "        self.encoder = smp.models.densenet201(pretrained=True)\n",
    "        num_ftrs = self.encoder.classifier.in_features\n",
    "        self.encoder.classifier = nn.Linear(num_ftrs, 1)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.encoder(x)\n",
    "        return x\n",
    "    \n",
    "# initialize the classifier model\n",
    "model = Densenet()\n",
    "\n",
    "# move the model to GPU if available\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = model.to(device)\n",
    "\n",
    "# define the loss function and optimizer\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 5: Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# set the number of epochs for training\n",
    "num_epochs = 50\n",
    "\n",
    "# keep track of training loss for each epoch\n",
    "train_loss_history = []\n",
    "\n",
    "# start training\n",
    "for epoch in range(num_epochs):\n",
    "    # set the model to training mode\n",
    "    model.train()\n",
    "    \n",
    "    # keep track of training loss for this epoch\n",
    "    epoch_loss = 0\n",
    "    \n",
    "    # loop through the training data\n",
    "    for (chart_img, sar_img), target in train_loader:\n",
    "        # move data to GPU if available\n",
    "        chart_img = chart_img.to(device)\n",
    "        sar_img = sar_img.to(device)\n",
    "        target = target.to(device)\n",
    "        \n",
    "        # clear gradients\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # forward pass\n",
    "        output = model(sar_img)\n",
    "        \n",
    "        # calculate loss\n",
    "        loss = criterion(output, target.float().unsqueeze(1))\n",
    "        \n",
    "        # backward pass and optimization\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        # accumulate loss for this epoch\n",
    "        epoch_loss += loss.item()\n",
    "        \n",
    "    # average loss for this epoch\n",
    "    epoch_loss = epoch_loss / len(train_loader)\n",
    "    train_loss_history.append(epoch_loss)\n",
    "    \n",
    "    # print loss for this epoch\n",
    "    print(\"Epoch {}/{} - Train Loss: {:.6f}\".format(epoch+1, num_epochs, epoch_loss))\n",
    "    \n",
    "# save the trained model\n",
    "torch.save(model.state_dict(), \"trained_model.pth\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "See an example from https://github.com/shounak8/AIML_Tutotials/blob/master/Deep_Learning/PyTorch/santa_or_not/santa_pytorch_pretrained_model.ipynb for working with pretrained models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Working: Training and saving checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name     | Type             | Params\n",
      "----------------------------------------------\n",
      "0 | densenet | Unet             | 28.6 M\n",
      "1 | loss_fn  | CrossEntropyLoss | 0     \n",
      "----------------------------------------------\n",
      "28.6 M    Trainable params\n",
      "0         Non-trainable params\n",
      "28.6 M    Total params\n",
      "114.326   Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 1/1 [00:02<00:00,  2.69s/it, loss=0, v_num=12]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=10` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 1/1 [00:03<00:00,  3.92s/it, loss=0, v_num=12]\n"
     ]
    }
   ],
   "source": [
    "## IMPORT THE MODULES ##\n",
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "import pytorch_lightning as pl\n",
    "import segmentation_models_pytorch as smp\n",
    "from skimage import io\n",
    "from torchvision import transforms\n",
    "import torch.nn as nn\n",
    "from pytorch_lightning import Trainer\n",
    "import torch.utils.data as data_utils\n",
    "\n",
    "\n",
    "#### LOAD THE DATA : ATTEMPT 3 ###\n",
    "sar_name = \"/Users/meghanplumridge/Desktop/CNN_sar_data/lbls_WS_20181202T_00088_[10752,1280]_256x256.tiff\"\n",
    "chart_name = \"/Users/meghanplumridge/Desktop/CNN_chart_data/ftrs_WS_20181202T_00088_[10752,1280]_256x256.tiff\"\n",
    "\n",
    "\n",
    "### THIS CODE FAILS WITH ERROR RuntimeError: Given groups=1, weight of size [64, 3, 7, 7], expected input[1, 1, 256, 256] to have 3 channels, but got 1 channels instead #\n",
    "#sar = io.imread(sar_name).copy()  # take all bands for shape of 256 x 256 x 3\n",
    "## To solve the error: RuntimeError: Given groups=1, weight of size [64, 3, 7, 7], expected input[1, 1, 256, 256] to have 3 channels, but got 1 channels instead #\n",
    "## This code checks if the SAR data has only 1 channel and, if so, replicates the single channel 3 times to make it have 3 channels. This should ensure that the input to the model has the correct number of channels.\n",
    "#if sar.shape[-1] == 1:\n",
    "#    sar = np.repeat(sar, 3, axis=-1)\n",
    "#chart = io.imread(chart_name).copy()[:, :, 0]  # take red band only for shape of 256 x 256 x 1\n",
    "#chart[chart < 80] = 0  # binarise to water\n",
    "#chart[chart >= 80] = 255  # binarise to ice\n",
    "\n",
    "### TRY AGAIN ###\n",
    "sar = io.imread(sar_name).copy()[:, :, np.newaxis]  # add a channel dimension for shape of 256 x 256 x 1\n",
    "sar = np.repeat(sar, 3, axis=2)  # repeat the same SAR data to create 3-channel image\n",
    "chart = io.imread(chart_name).copy()[:, :, 0]  # take red band only for shape of 256 x 256 x 1\n",
    "chart[chart < 80] = 0  # binarise to water\n",
    "chart[chart >= 80] = 255  # binarise to ice\n",
    "\n",
    "\n",
    "## TRANSFORM THE DATA ##\n",
    "# Convert SAR data to PyTorch tensor\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "tensor_sar = transform(sar)\n",
    "tensor_chart = transform(chart)\n",
    "\n",
    "# define the training data\n",
    "train_sar = tensor_sar.unsqueeze(0)  # add a batch dimension to tensor_sar\n",
    "train_chart = tensor_chart.unsqueeze(0)  # add a batch dimension to chart\n",
    "train_data = data_utils.TensorDataset(train_sar, train_chart)\n",
    "\n",
    "# define the data loader\n",
    "train_loader = torch.utils.data.DataLoader(train_data, batch_size=1, shuffle=True)\n",
    "\n",
    "# To fix the following error: \"URLError: <urlopen error [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: certificate has expired (_ssl.c:1129)>\" #\n",
    "import ssl\n",
    "ssl._create_default_https_context = ssl._create_unverified_context\n",
    "\n",
    "## DEFINE THE MODEL ##\n",
    "class Model(pl.LightningModule):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.densenet = smp.Unet('densenet201', encoder_weights='imagenet', in_channels=3)\n",
    "        # Replace output of Fully Connected Layer with number of labels for our classification problem\n",
    "        self.densenet.classifier = nn.Linear(in_features=512, out_features=2)\n",
    "        # Optimizer\n",
    "        self.optimizer = torch.optim.Adam(self.densenet.parameters(), lr=3e-4)\n",
    "        # Loss Function\n",
    "        self.loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Define how the input x should pass through the layers of the model\n",
    "        x = self.densenet(x)\n",
    "        return x\n",
    "\n",
    "    ### THE \"TOO MANY VALUES ERROR CONTINUED, even after updating train_dataloader.\"\n",
    "    # Define what happens during one training step on one batch of data\n",
    "    #def training_step(self, batch, batch_idx):\n",
    "    #    x, y = batch\n",
    "    #    y_pred = self.forward(x)\n",
    "    #    loss = self.loss_fn(y_pred, y)\n",
    "    #    self.log('train_loss', loss)\n",
    "    #    return loss\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "    # Define what happens during one training step on one batch of data\n",
    "        x, y = batch\n",
    "        y_pred = self.forward(x)\n",
    "        loss = self.loss_fn(y_pred, y.squeeze(1).long())\n",
    "        self.log('train_loss', loss)\n",
    "        return loss\n",
    "\n",
    "    # Return a list of optimizers and LR schedulers to use in training\n",
    "    def configure_optimizers(self):\n",
    "        return self.optimizer\n",
    "\n",
    "    def train_dataloader(self):\n",
    "    # Replace with your own DataLoader object\n",
    "        train_data = [(tensor_sar, tensor_chart)]\n",
    "        input_data = torch.stack([data[0] for data in train_data])\n",
    "        target_data = torch.stack([data[1] for data in train_data])\n",
    "        train_loader = torch.utils.data.DataLoader(list(zip(input_data, target_data)), batch_size=1, shuffle=True)\n",
    "        return train_loader\n",
    "    \n",
    "    ### THIS RETURNS ERROR ValueError: too many values to unpack (expected 2) ###\n",
    "    #def train_dataloader(self):\n",
    "    #    return train_loader\n",
    "\n",
    "    ### THIS ALSO DID NOT WORK - ValueError: not enough values to unpack (expected 2, got 1) ###\n",
    "    #def train_dataloader(self):\n",
    "    ## Replace with your own DataLoader object\n",
    "    #    train_data = [(tensor_sar, chart)]\n",
    "    #    train_loader = torch.utils.data.DataLoader(train_data, batch_size=1, shuffle=True)\n",
    "    #    return train_loader\n",
    "    \n",
    "    ### THIS DID NOT WORK - ValueError: too many values to unpack (expected 2) ###\n",
    "    ## Return a DataLoader object for the training data\n",
    "    #def train_dataloader(self):\n",
    "    #    return torch.utils.data.DataLoader(tensor_sar, batch_size=1)\n",
    "\n",
    "## TRAIN THE MODEL ##\n",
    "model = Model()\n",
    "\n",
    "# Instantiate a Trainer object and train the model\n",
    "trainer = Trainer(\n",
    "    gpus=0,\n",
    "    accelerator=\"cpu\", \n",
    "    max_epochs=10 \n",
    "    #callbacks=[early_stop_callback],\n",
    "    )\n",
    "\n",
    "trainer.fit(model, train_loader)\n",
    "\n",
    "# Save the trained model to a file\n",
    "trainer.save_checkpoint(\"/Users/meghanplumridge/Desktop/checkpoint.ckpt\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Working: Both train and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/meghanplumridge/miniconda3/lib/python3.9/site-packages/pytorch_lightning/trainer/connectors/accelerator_connector.py:474: LightningDeprecationWarning: Setting `Trainer(gpus=0)` is deprecated in v1.7 and will be removed in v2.0. Please use `Trainer(accelerator='gpu', devices=0)` instead.\n",
      "  rank_zero_deprecation(\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name     | Type             | Params\n",
      "----------------------------------------------\n",
      "0 | densenet | Unet             | 28.6 M\n",
      "1 | loss_fn  | CrossEntropyLoss | 0     \n",
      "----------------------------------------------\n",
      "28.6 M    Trainable params\n",
      "0         Non-trainable params\n",
      "28.6 M    Total params\n",
      "114.326   Total estimated model params size (MB)\n",
      "/Users/meghanplumridge/miniconda3/lib/python3.9/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:224: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n",
      "/Users/meghanplumridge/miniconda3/lib/python3.9/site-packages/pytorch_lightning/trainer/trainer.py:1609: PossibleUserWarning: The number of training batches (1) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0:   0%|          | 0/1 [53:16<?, ?it/s].88s/it, loss=0, v_num=13]\n",
      "Epoch 9: 100%|██████████| 1/1 [00:01<00:00,  1.22s/it, loss=0, v_num=13]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=10` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 1/1 [00:01<00:00,  1.86s/it, loss=0, v_num=13]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/meghanplumridge/miniconda3/lib/python3.9/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:224: PossibleUserWarning: The dataloader, test_dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing DataLoader 0: 100%|██████████| 1/1 [00:00<00:00,  2.77it/s]\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss                   0.0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'test_loss': 0.0}]"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## IMPORT THE MODULES ##\n",
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "import pytorch_lightning as pl\n",
    "import segmentation_models_pytorch as smp\n",
    "from skimage import io\n",
    "from torchvision import transforms\n",
    "import torch.nn as nn\n",
    "from pytorch_lightning import Trainer\n",
    "import torch.utils.data as data_utils\n",
    "\n",
    "####################################################################################\n",
    "\n",
    "#### LOAD THE TRAINING DATA : ATTEMPT 3 ###\n",
    "sar_name = \"/Users/meghanplumridge/Desktop/CNN_sar_data/lbls_WS_20181202T_00088_[10752,1280]_256x256.tiff\"\n",
    "chart_name = \"/Users/meghanplumridge/Desktop/CNN_chart_data/ftrs_WS_20181202T_00088_[10752,1280]_256x256.tiff\"\n",
    "\n",
    "\n",
    "### THIS CODE FAILS WITH ERROR RuntimeError: Given groups=1, weight of size [64, 3, 7, 7], expected input[1, 1, 256, 256] to have 3 channels, but got 1 channels instead #\n",
    "#sar = io.imread(sar_name).copy()  # take all bands for shape of 256 x 256 x 3\n",
    "## To solve the error: RuntimeError: Given groups=1, weight of size [64, 3, 7, 7], expected input[1, 1, 256, 256] to have 3 channels, but got 1 channels instead #\n",
    "## This code checks if the SAR data has only 1 channel and, if so, replicates the single channel 3 times to make it have 3 channels. This should ensure that the input to the model has the correct number of channels.\n",
    "#if sar.shape[-1] == 1:\n",
    "#    sar = np.repeat(sar, 3, axis=-1)\n",
    "#chart = io.imread(chart_name).copy()[:, :, 0]  # take red band only for shape of 256 x 256 x 1\n",
    "#chart[chart < 80] = 0  # binarise to water\n",
    "#chart[chart >= 80] = 255  # binarise to ice\n",
    "\n",
    "### TRY AGAIN ###\n",
    "sar = io.imread(sar_name).copy()[:, :, np.newaxis]  # add a channel dimension for shape of 256 x 256 x 1\n",
    "sar = np.repeat(sar, 3, axis=2)  # repeat the same SAR data to create 3-channel image\n",
    "chart = io.imread(chart_name).copy()[:, :, 0]  # take red band only for shape of 256 x 256 x 1\n",
    "chart[chart < 80] = 0  # binarise to water\n",
    "chart[chart >= 80] = 255  # binarise to ice\n",
    "\n",
    "\n",
    "## TRANSFORM THE DATA ##\n",
    "# Convert SAR data to PyTorch tensor\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "tensor_sar = transform(sar)\n",
    "tensor_chart = transform(chart)\n",
    "\n",
    "# define the training data\n",
    "train_sar = tensor_sar.unsqueeze(0)  # add a batch dimension to tensor_sar\n",
    "train_chart = tensor_chart.unsqueeze(0)  # add a batch dimension to chart\n",
    "train_data = data_utils.TensorDataset(train_sar, train_chart)\n",
    "\n",
    "# define the data loader\n",
    "train_loader = torch.utils.data.DataLoader(train_data, batch_size=1, shuffle=True)\n",
    "\n",
    "####################################################################################\n",
    "\n",
    "#### LOAD THE TEST DATA ####\n",
    "\n",
    "## LOAD THE TEST DATA ##\n",
    "test_sar_name = \"/Users/meghanplumridge/Desktop/CNN_sar_data/lbls_WS_20181202T_00088_[10752,1280]_256x256.tiff\"\n",
    "test_chart_name = \"/Users/meghanplumridge/Desktop/CNN_chart_data/ftrs_WS_20181202T_00088_[10752,1280]_256x256.tiff\"\n",
    "\n",
    "\n",
    "test_sar = io.imread(test_sar_name).copy()[:, :, np.newaxis]  # add a channel dimension for shape of 256 x 256 x 1\n",
    "test_sar = np.repeat(test_sar, 3, axis=2)  # repeat the same SAR data to create 3-channel image\n",
    "test_chart = io.imread(test_chart_name).copy()[:, :, 0]  # take red band only for shape of 256 x 256 x 1\n",
    "test_chart[test_chart < 80] = 0  # binarise to water\n",
    "test_chart[test_chart >= 80] = 255  # binarise to ice\n",
    "\n",
    "# Convert SAR data to PyTorch tensor\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "test_tensor_sar = transform(test_sar)\n",
    "test_tensor_chart = transform(test_chart)\n",
    "\n",
    "# define the test data\n",
    "test_sar = test_tensor_sar.unsqueeze(0)  # add a batch dimension to tensor_sar\n",
    "test_chart = test_tensor_chart.unsqueeze(0)  # add a batch dimension to chart\n",
    "test_data = data_utils.TensorDataset(test_sar, test_chart)\n",
    "\n",
    "# define the data loader\n",
    "test_loader = torch.utils.data.DataLoader(test_data, batch_size=1, shuffle=False)\n",
    "\n",
    "####################################################################################\n",
    "\n",
    "# To fix the following error: \"URLError: <urlopen error [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: certificate has expired (_ssl.c:1129)>\" #\n",
    "import ssl\n",
    "ssl._create_default_https_context = ssl._create_unverified_context\n",
    "\n",
    "## DEFINE THE MODEL ##\n",
    "class Model(pl.LightningModule):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.densenet = smp.Unet('densenet201', encoder_weights='imagenet', in_channels=3)\n",
    "        # Replace output of Fully Connected Layer with number of labels for our classification problem\n",
    "        self.densenet.classifier = nn.Linear(in_features=512, out_features=2)\n",
    "        # Optimizer\n",
    "        self.optimizer = torch.optim.Adam(self.densenet.parameters(), lr=3e-4)\n",
    "        # Loss Function\n",
    "        self.loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Define how the input x should pass through the layers of the model\n",
    "        x = self.densenet(x)\n",
    "        return x\n",
    "\n",
    "    ### THE \"TOO MANY VALUES ERROR CONTINUED, even after updating train_dataloader.\"\n",
    "    # Define what happens during one training step on one batch of data\n",
    "    #def training_step(self, batch, batch_idx):\n",
    "    #    x, y = batch\n",
    "    #    y_pred = self.forward(x)\n",
    "    #    loss = self.loss_fn(y_pred, y)\n",
    "    #    self.log('train_loss', loss)\n",
    "    #    return loss\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "    # Define what happens during one training step on one batch of data\n",
    "        x, y = batch\n",
    "        y_pred = self.forward(x)\n",
    "        loss = self.loss_fn(y_pred, y.squeeze(1).long())\n",
    "        self.log('train_loss', loss)\n",
    "        return loss\n",
    "\n",
    "    # Return a list of optimizers and LR schedulers to use in training\n",
    "    def configure_optimizers(self):\n",
    "        return self.optimizer\n",
    "\n",
    "    def train_dataloader(self):\n",
    "    # Replace with your own DataLoader object\n",
    "        train_data = [(tensor_sar, tensor_chart)]\n",
    "        input_data = torch.stack([data[0] for data in train_data])\n",
    "        target_data = torch.stack([data[1] for data in train_data])\n",
    "        train_loader = torch.utils.data.DataLoader(list(zip(input_data, target_data)), batch_size=1, shuffle=True)\n",
    "        return train_loader\n",
    "\n",
    "    def test_step(self, batch, batch_idx):\n",
    "        # Define what happens during one test step on one batch of data\n",
    "        x, y = batch\n",
    "        y_pred = self.forward(x)\n",
    "        loss = self.loss_fn(y_pred, y.squeeze(1).long())\n",
    "        self.log('test_loss', loss)\n",
    "        return loss\n",
    "\n",
    "    def test_dataloader(self):\n",
    "        # Replace with your own DataLoader object\n",
    "        return test_loader\n",
    "    \n",
    "    ### THIS RETURNS ERROR ValueError: too many values to unpack (expected 2) ###\n",
    "    #def train_dataloader(self):\n",
    "    #    return train_loader\n",
    "\n",
    "    ### THIS ALSO DID NOT WORK - ValueError: not enough values to unpack (expected 2, got 1) ###\n",
    "    #def train_dataloader(self):\n",
    "    ## Replace with your own DataLoader object\n",
    "    #    train_data = [(tensor_sar, chart)]\n",
    "    #    train_loader = torch.utils.data.DataLoader(train_data, batch_size=1, shuffle=True)\n",
    "    #    return train_loader\n",
    "    \n",
    "    ### THIS DID NOT WORK - ValueError: too many values to unpack (expected 2) ###\n",
    "    ## Return a DataLoader object for the training data\n",
    "    #def train_dataloader(self):\n",
    "    #    return torch.utils.data.DataLoader(tensor_sar, batch_size=1)\n",
    "\n",
    "## TRAIN THE MODEL ##\n",
    "model = Model()\n",
    "\n",
    "# Instantiate a Trainer object and train the model\n",
    "trainer = Trainer(\n",
    "    gpus=0,\n",
    "    accelerator=\"cpu\", \n",
    "    max_epochs=10 \n",
    "    #callbacks=[early_stop_callback],\n",
    "    )\n",
    "\n",
    "trainer.fit(model, train_loader)\n",
    "\n",
    "# Save the trained model to a file\n",
    "trainer.save_checkpoint(\"/Users/meghanplumridge/Desktop/checkpoint.ckpt\")\n",
    "\n",
    "# Run the model\n",
    "trainer.test(model, test_loader)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "base"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
