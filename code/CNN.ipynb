{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For the data loader\n",
    "import os\n",
    "#import cv2\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "# For data augmentation\n",
    "from torchvision import transforms\n",
    "\n",
    "# For creating the model\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import segmentation_models_pytorch as smp\n",
    "\n",
    "# For training the model\n",
    "import numpy as np\n",
    "\n",
    "# For tracking the model\n",
    "import wandb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 1: Load the data (dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The SeaIceData class contains functions for loading the data and creating a custom dataset\n",
    "class SeaIceDataset(Dataset):\n",
    "    def __init__(self, sar_path: str, chart_path: str, transform=None, augmentation=None):\n",
    "        self.sar_path = sar_path\n",
    "        self.sar_files = os.listdir(self.sar_path)\n",
    "        self.chart_path = chart_path\n",
    "        self.chart_files = os.listdir(self.chart_path)\n",
    "        self.transform = transform\n",
    "        ### apply augmentation at the data loader stage or later stage (for training data only?) ###\n",
    "        # self.augmentation = augmentation\n",
    "        # self.train_dataloader =  train_dataloader\n",
    "\n",
    "# Fetch the data\n",
    "    def __getitem__(self, index):\n",
    "        sar_img = os.path.join(self.sar_path, self.sar_files[index])\n",
    "        chart_img = os.path.join(self.chart_path, self.chart_files[index]) \n",
    "\n",
    "        ### Could/should we use cv2 or io for reading the data?\n",
    "        \n",
    "        sar = io.imread(sar_img).copy()  # take all bands for shape of 256 x 256 x 3\n",
    "        chart = io.imread(chart_img).copy()[:, :, 0]  # take red band only for shape of 256 x 256 x 1\n",
    "        chart[chart < 80] = 0  # binarise to water\n",
    "        chart[chart >= 80] = 255  # binarise to ice\n",
    "        sample = {\"sar\": sar, \"chart\": chart}\n",
    "\n",
    "        if self.transform:\n",
    "            sample = {\"sar\": self.transform(sar), \"chart\": self.transform(chart).squeeze(0).long()}\n",
    "        return sample\n",
    "\n",
    "        ### TBC if needed at this stage ###\n",
    "        #if self.augmentation:\n",
    "            #sample = {\"sar\": self.augmentation(sar), \"chart\": self.augmentation(chart)}\n",
    "\n",
    "# Keep going through all data    \n",
    "    def __len__(self):\n",
    "        return len(self.sar_files)\n",
    "\n",
    "### TBC if needed at this stage - Transformations/augmentation for training data only ###\n",
    "#train_transform = transforms.Compose([\n",
    "#    transforms.RandomHorizontalFlip(),\n",
    "#    transforms.RandomRotation(30)\n",
    "#])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 2: Data Augmentation\n",
    "\n",
    "See: https://github.com/qubvel/segmentation_models.pytorch/blob/master/examples/cars%20segmentation%20(camvid).ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 3: Split dataset into training/testing/validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split the data into training and validation sets\n",
    "train_data = SARData(sar_dir, chart_dir, train_transform, train=True)\n",
    "val_data = SARData(sar_dir, chart_dir, val_transform, train=False)\n",
    "\n",
    "# create dataloaders for the training and validation sets\n",
    "train_dataloader = DataLoader(train_data, batch_size=16, shuffle=True)\n",
    "val_dataloader = DataLoader(val_data, batch_size=16, shuffle=False)\n",
    "\n",
    "### Example from Andrew\n",
    "train_dataset = SeaIceDataset(sar_path=\"./sar\", chart_path=\"./chart\", transform=transforms.ToTensor())\n",
    "train_dataloader = DataLoader(train_dataset, shuffle=True)\n",
    "val_dataset = SeaIceDataset(sar_path=\"./sar\", chart_path=\"./chart\", transform=transforms.ToTensor())\n",
    "val_dataloader = DataLoader(val_dataset, shuffle=False)\n",
    "\n",
    "### From https://github.com/qubvel/segmentation_models.pytorch/blob/master/examples/cars%20segmentation%20(camvid).ipynb\n",
    "\n",
    "train_dataset = Dataset(\n",
    "    x_train_dir, \n",
    "    y_train_dir, \n",
    "    augmentation=get_training_augmentation(), \n",
    "    preprocessing=get_preprocessing(preprocessing_fn),\n",
    "    classes=CLASSES,\n",
    ")\n",
    "\n",
    "valid_dataset = Dataset(\n",
    "    x_valid_dir, \n",
    "    y_valid_dir, \n",
    "    augmentation=get_validation_augmentation(), \n",
    "    preprocessing=get_preprocessing(preprocessing_fn),\n",
    "    classes=CLASSES,\n",
    ")\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=8, shuffle=True, num_workers=12)\n",
    "valid_loader = DataLoader(valid_dataset, batch_size=1, shuffle=False, num_workers=4)\n",
    "\n",
    "\n",
    "### EXAMPLE FROM https://github.com/MohammadBakir/Pytorch-Flower-Image-Classification/blob/master/Image%20Classifier%20Densenet201.py\n",
    "#Defining data directories, modify accordingly\n",
    "data_dir = './flower_data/flower_data'\n",
    "train_dir = data_dir + '/train'\n",
    "valid_dir = data_dir + '/valid'\n",
    "test_dir = data_dir + '/test'\n",
    "\n",
    "#Define transforms for the training and validation sets\n",
    "#Using pretrained Pytorch model trained on image sizes 224. Modify ResizedCrop and CenterCrop according to needs. \n",
    "data_transforms_train = transforms.Compose([transforms.RandomResizedCrop(256),\n",
    "                                            transforms.RandomRotation(30),\n",
    "                                            transforms.ColorJitter(),\n",
    "                                            transforms.RandomHorizontalFlip(),\n",
    "                                            transforms.CenterCrop(224), \n",
    "                                            transforms.ToTensor(),\n",
    "                                            transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])])\n",
    "\n",
    "data_transforms_validation = transforms.Compose([transforms.Resize(256),\n",
    "                                                 transforms.CenterCrop(224),\n",
    "                                                 transforms.ToTensor(),\n",
    "                                                 transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])])\n",
    "\n",
    "data_transforms_test = transforms.Compose([transforms.Resize(256),\n",
    "                                                 transforms.CenterCrop(224),\n",
    "                                                 transforms.ToTensor(),\n",
    "                                                 transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])])\n",
    "\n",
    "#Load the datasets with ImageFolder\n",
    "image_dataset_train = datasets.ImageFolder(train_dir, transform = data_transforms_train)\n",
    "\n",
    "image_dataset_validation = datasets.ImageFolder(valid_dir, transform = data_transforms_validation)\n",
    "\n",
    "image_dataset_test = datasets.ImageFolder(test_dir, transform = data_transforms_validation)\n",
    "\n",
    "\n",
    "# Using the image datasets and the trainforms, define the dataloaders\n",
    "#batch size and num workers can be modified accordingly. \n",
    "batch_size =256\n",
    "num_workers=4\n",
    " \n",
    "\n",
    "dataloader_train = torch.utils.data.DataLoader(image_dataset_train, batch_size=batch_size,\n",
    "                                               num_workers=num_workers, shuffle=True)\n",
    "\n",
    "dataloader_valid = torch.utils.data.DataLoader(image_dataset_validation, batch_size=batch_size,\n",
    "                                               num_workers=num_workers, shuffle=True)\n",
    "\n",
    "dataloader_test = torch.utils.data.DataLoader(image_dataset_test, batch_size=batch_size,\n",
    "                                               num_workers=num_workers, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 4: Create the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "__init__() got an unexpected keyword argument 'pretrained'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/Users/meghanplumridge/Desktop/CNN.ipynb Cell 8\u001b[0m in \u001b[0;36m<cell line: 10>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/meghanplumridge/Desktop/CNN.ipynb#X11sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39m### See https://pytorch.org/hub/pytorch_vision_densenet/ for info about Densenet\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/meghanplumridge/Desktop/CNN.ipynb#X11sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m \n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/meghanplumridge/Desktop/CNN.ipynb#X11sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m \u001b[39m### See https://paperswithcode.com/lib/torchvision/densenet for documentation on how to set this up!!!!\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/meghanplumridge/Desktop/CNN.ipynb#X11sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m \n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/meghanplumridge/Desktop/CNN.ipynb#X11sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m \u001b[39m# Using Densetnet201 from https://segmentation-modelspytorch.readthedocs.io/en/latest/ \u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/meghanplumridge/Desktop/CNN.ipynb#X11sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m densenet \u001b[39m=\u001b[39m smp\u001b[39m.\u001b[39;49mUnet(\u001b[39m'\u001b[39;49m\u001b[39mdensenet201\u001b[39;49m\u001b[39m'\u001b[39;49m, encoder_weights\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mimagenet\u001b[39;49m\u001b[39m'\u001b[39;49m, pretrained\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/meghanplumridge/Desktop/CNN.ipynb#X11sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m \u001b[39m### The model has been pre-trained on XXX so we need to transform our data to match\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/meghanplumridge/Desktop/CNN.ipynb#X11sZmlsZQ%3D%3D?line=15'>16</a>\u001b[0m ENCODER \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mse_resnext50_32x4d\u001b[39m\u001b[39m'\u001b[39m\n",
      "\u001b[0;31mTypeError\u001b[0m: __init__() got an unexpected keyword argument 'pretrained'"
     ]
    }
   ],
   "source": [
    "### See https://pytorch.org/hub/pytorch_vision_densenet/ for info about Densenet\n",
    "\n",
    "### See https://paperswithcode.com/lib/torchvision/densenet for documentation on how to set this up!!!!\n",
    "\n",
    "#### MOST HELPFUL SO FAR ####\n",
    "## 1. Work through this: https://github.com/shounak8/AIML_Tutotials/blob/master/Deep_Learning/PyTorch/santa_or_not/santa_pytorch_pretrained_model.ipynb \n",
    "## 2. Then this: https://www.kaggle.com/code/balraj98/unet-with-pretrained-resnet50-encoder-pytorch\n",
    "## 3. Ot this: https://github.com/MohammadBakir/Pytorch-Flower-Image-Classification/blob/master/Image%20Classifier%20Densenet201.py \n",
    "\n",
    "# Using Densetnet201 from https://segmentation-modelspytorch.readthedocs.io/en/latest/ \n",
    "densenet = smp.Unet('densenet201', encoder_weights='imagenet', pretrained=True)\n",
    "\n",
    "### The model has been pre-trained on XXX so we need to transform our data to match\n",
    "\n",
    "### Densenet expects 256 size?\n",
    "\n",
    "\n",
    "\n",
    "ENCODER = 'se_resnext50_32x4d'\n",
    "ENCODER_WEIGHTS = 'imagenet'\n",
    "CLASSES = ['car']\n",
    "ACTIVATION = 'sigmoid' # could be None for logits or 'softmax2d' for multiclass segmentation\n",
    "DEVICE = 'cuda'\n",
    "\n",
    "# create segmentation model with pretrained encoder\n",
    "model = smp.FPN(\n",
    "    encoder_name=ENCODER, \n",
    "    encoder_weights=ENCODER_WEIGHTS, \n",
    "    classes=len(CLASSES), \n",
    "    activation=ACTIVATION,\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "# create a custom classifier using the densenet201 encoder\n",
    "class Densenet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Densenet, self).__init__()\n",
    "        self.encoder = smp.models.densenet201(pretrained=True)\n",
    "        num_ftrs = self.encoder.classifier.in_features\n",
    "        self.encoder.classifier = nn.Linear(num_ftrs, 1)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.encoder(x)\n",
    "        return x\n",
    "    \n",
    "# initialize the classifier model\n",
    "model = Densenet()\n",
    "\n",
    "# move the model to GPU if available\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = model.to(device)\n",
    "\n",
    "# define the loss function and optimizer\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# set the number of epochs for training\n",
    "num_epochs = 50\n",
    "\n",
    "# keep track of training loss for each epoch\n",
    "train_loss_history = []\n",
    "\n",
    "# start training\n",
    "for epoch in range(num_epochs):\n",
    "    # set the model to training mode\n",
    "    model.train()\n",
    "    \n",
    "    # keep track of training loss for this epoch\n",
    "    epoch_loss = 0\n",
    "    \n",
    "    # loop through the training data\n",
    "    for (chart_img, sar_img), target in train_loader:\n",
    "        # move data to GPU if available\n",
    "        chart_img = chart_img.to(device)\n",
    "        sar_img = sar_img.to(device)\n",
    "        target = target.to(device)\n",
    "        \n",
    "        # clear gradients\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # forward pass\n",
    "        output = model(sar_img)\n",
    "        \n",
    "        # calculate loss\n",
    "        loss = criterion(output, target.float().unsqueeze(1))\n",
    "        \n",
    "        # backward pass and optimization\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        # accumulate loss for this epoch\n",
    "        epoch_loss += loss.item()\n",
    "        \n",
    "    # average loss for this epoch\n",
    "    epoch_loss = epoch_loss / len(train_loader)\n",
    "    train_loss_history.append(epoch_loss)\n",
    "    \n",
    "    # print loss for this epoch\n",
    "    print(\"Epoch {}/{} - Train Loss: {:.6f}\".format(epoch+1, num_epochs, epoch_loss))\n",
    "    \n",
    "# save the trained model\n",
    "torch.save(model.state_dict(), \"trained_model.pth\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run & evaluate model performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## From Andrew\n",
    "\n",
    "trainer.fit(segmenter, train_dataloader, val_dataloader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tune hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import segmentation_models_pytorch as smp\n",
    "from PIL import Image\n",
    "\n",
    "# Load the SAR image and the labelled ice chart\n",
    "sar_image = np.array(Image.open(\"sar_image.tif\"))\n",
    "ice_chart = np.array(Image.open(\"ice_chart.tif\"))\n",
    "\n",
    "# Resize and normalize the images\n",
    "resize = (256, 256)\n",
    "sar_image = np.array(Image.fromarray(sar_image).resize(resize))\n",
    "sar_image = sar_image.astype(np.float32) / 65535.0 # TIFF images are typically 16-bit, so normalize to [0, 1]\n",
    "ice_chart = np.array(Image.fromarray(ice_chart).resize(resize))\n",
    "ice_chart = ice_chart.astype(np.float32) / 255.0\n",
    "\n",
    "# Load the UNet model with a ResNet34 encoder and pre-trained ImageNet weights\n",
    "model = smp.Unet('resnet34', encoder_weights='imagenet')\n",
    "\n",
    "# Prepare the SAR image for inference\n",
    "sar_image_tensor = torch.from_numpy(sar_image).to(torch.float32).unsqueeze(0).unsqueeze(0) # add batch and channel dimensions\n",
    "preds = model.predict(sar_image_tensor)\n",
    "\n",
    "# Threshold the predicted segmentation mask\n",
    "threshold = 0.5\n",
    "binary_preds = (preds > threshold).astype(np.uint8)\n",
    "\n",
    "# Evaluate the binary mask\n",
    "accuracy = np.mean(binary_preds == ice_chart)\n",
    "print(\"Accuracy:\", accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An example from https://github.com/shounak8/AIML_Tutotials/blob/master/Deep_Learning/PyTorch/santa_or_not/santa_pytorch_pretrained_model.ipynb "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Cannot handle this data type: (1, 1, 3), <f4",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[0;32m~/miniconda3/lib/python3.9/site-packages/PIL/Image.py:3080\u001b[0m, in \u001b[0;36mfromarray\u001b[0;34m(obj, mode)\u001b[0m\n\u001b[1;32m   3079\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m-> 3080\u001b[0m     mode, rawmode \u001b[39m=\u001b[39m _fromarray_typemap[typekey]\n\u001b[1;32m   3081\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mKeyError\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n",
      "\u001b[0;31mKeyError\u001b[0m: ((1, 1, 3), '<f4')",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/Users/meghanplumridge/Desktop/CNN.ipynb Cell 23\u001b[0m in \u001b[0;36m<cell line: 13>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/meghanplumridge/Desktop/CNN.ipynb#X46sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m \u001b[39m# Resize and normalize the images\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/meghanplumridge/Desktop/CNN.ipynb#X46sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m resize \u001b[39m=\u001b[39m (\u001b[39m256\u001b[39m, \u001b[39m256\u001b[39m)\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/meghanplumridge/Desktop/CNN.ipynb#X46sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m sar_image \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39marray(Image\u001b[39m.\u001b[39;49mfromarray(sar_image)\u001b[39m.\u001b[39mresize(resize))\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/meghanplumridge/Desktop/CNN.ipynb#X46sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m sar_image \u001b[39m=\u001b[39m sar_image\u001b[39m.\u001b[39mastype(np\u001b[39m.\u001b[39mfloat32) \u001b[39m/\u001b[39m \u001b[39m65535.0\u001b[39m \u001b[39m# TIFF images are typically 16-bit, so normalize to [0, 1]\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/meghanplumridge/Desktop/CNN.ipynb#X46sZmlsZQ%3D%3D?line=14'>15</a>\u001b[0m ice_chart \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39marray(Image\u001b[39m.\u001b[39mfromarray(ice_chart)\u001b[39m.\u001b[39mresize(resize))\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.9/site-packages/PIL/Image.py:3083\u001b[0m, in \u001b[0;36mfromarray\u001b[0;34m(obj, mode)\u001b[0m\n\u001b[1;32m   3081\u001b[0m     \u001b[39mexcept\u001b[39;00m \u001b[39mKeyError\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m   3082\u001b[0m         msg \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mCannot handle this data type: \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m, \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m\"\u001b[39m \u001b[39m%\u001b[39m typekey\n\u001b[0;32m-> 3083\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mTypeError\u001b[39;00m(msg) \u001b[39mfrom\u001b[39;00m \u001b[39me\u001b[39;00m\n\u001b[1;32m   3084\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   3085\u001b[0m     rawmode \u001b[39m=\u001b[39m mode\n",
      "\u001b[0;31mTypeError\u001b[0m: Cannot handle this data type: (1, 1, 3), <f4"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import segmentation_models_pytorch as smp\n",
    "from PIL import Image\n",
    "import tifffile as tiff\n",
    "\n",
    "# Load the SAR image and the labelled ice chart\n",
    "sar_image = np.array(tiff.imread(\"/Users/meghanplumridge/Desktop/S1B_EW_GRDM_1SDH_20181210T085100_20181210T085208_013977_019EF9_260F.tif\"))\n",
    "ice_chart = np.array(tiff.imread(\"20181209.tiff\"))\n",
    "\n",
    "# Resize and normalize the images\n",
    "resize = (256, 256)\n",
    "sar_image = np.array(Image.fromarray(sar_image).resize(resize))\n",
    "sar_image = sar_image.astype(np.float32) / 65535.0 # TIFF images are typically 16-bit, so normalize to [0, 1]\n",
    "ice_chart = np.array(Image.fromarray(ice_chart).resize(resize))\n",
    "ice_chart = ice_chart.astype(np.float32) / 255.0\n",
    "\n",
    "# Load the UNet model with a ResNet34 encoder and pre-trained ImageNet weights\n",
    "model = smp.Unet('densenet201', encoder_weights='imagenet')\n",
    "\n",
    "# Replace the final layer with a binary classification layer\n",
    "num_ftrs = model.fc.in_features\n",
    "model.fc = torch.nn.Linear(num_ftrs, 1)\n",
    "\n",
    "# Freeze all layers except the final layer\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = False\n",
    "for param in model.fc.parameters():\n",
    "    param.requires_grad = True\n",
    "\n",
    "# Prepare the data for training\n",
    "sar_image_tensor = torch.from_numpy(sar_image).to(torch.float32).permute(2, 0, 1).unsqueeze(0) # add batch and channel dimensions\n",
    "ice_chart_tensor = torch.from_numpy(ice_chart).to(torch.float32).unsqueeze(0).unsqueeze(0) # add batch and channel dimensions\n",
    "\n",
    "# Train the model\n",
    "criterion = torch.nn.BCEWithLogitsLoss()\n",
    "optimizer = torch.optim.Adam(model.fc.parameters(), lr=0.001)\n",
    "num_epochs = 10\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "    outputs = model(sar_image_tensor)\n",
    "    loss = criterion(outputs, ice_chart_tensor)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "# Evaluate the model on the test data\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    preds = model(sar_image_tensor)\n",
    "    binary_preds = (preds > 0.5).squeeze().cpu().numpy().astype(np.uint8)\n",
    "\n",
    "# Evaluate the binary mask\n",
    "accuracy = np.mean(binary_preds == ice_chart)\n",
    "print(\"Accuracy:\", accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## IMPORT THE MODULES ##\n",
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "import pytorch_lightning as pl\n",
    "import segmentation_models_pytorch as smp\n",
    "from skimage import io\n",
    "from torchvision import transforms\n",
    "from torch.nn import Linear, CrossEntropyLoss\n",
    "from pytorch_lightning import Trainer\n",
    "\n",
    "\n",
    "\n",
    "### LOAD THE DATA : ATTEMPT 1 ##\n",
    "\n",
    "## Load the SAR image as training AND testing data for this example\n",
    "#sar_image_train = np.array(Image.open(\"sar_image.tif\"))\n",
    "#sar_image_test = np.array(Image.open(\"sar_image.tif\"))\n",
    "## Load the ice chart for evaluation of model performance\n",
    "#ice_chart = np.array(Image.open(\"ice_chart.tif\"))\n",
    "\n",
    "#### LOAD THE DATA : ATTEMPT 2 ###\n",
    "## In the directories are files called sar_image.tif and the corresponding ice_chart.tif\n",
    "#sar_path = \"/Users/meghanplumridge/Desktop/CNN_sar_data/\"\n",
    "#sar_files = os.listdir(sar_path)\n",
    "#chart_path = \"/Users/meghanplumridge/Desktop/CNN_chart_data/\"\n",
    "#chart_files = os.listdir(chart_path)\n",
    "#sar_name = os.path.join(sar_path, sar_files[i])\n",
    "#chart_name = os.path.join(chart_path, chart_files[i])\n",
    "\n",
    "#### LOAD THE DATA : ATTEMPT 3 ###\n",
    "sar_name = \"/Users/meghanplumridge/Desktop/CNN_sar_data/lbls_WS_20181202T_00088_[10752,1280]_256x256.tiff\"\n",
    "chart_name = \"/Users/meghanplumridge/Desktop/CNN_chart_data/ftrs_WS_20181202T_00088_[10752,1280]_256x256.tiff\"\n",
    "\n",
    "\n",
    "sar = io.imread(sar_name).copy()  # take all bands for shape of 256 x 256 x 3\n",
    "chart = io.imread(chart_name).copy()[:, :, 0]  # take red band only for shape of 256 x 256 x 1\n",
    "chart[chart < 80] = 0  # binarise to water\n",
    "chart[chart >= 80] = 255  # binarise to ice\n",
    "\n",
    "## TRANSFORM THE DATA ##\n",
    "# Data Transformer\n",
    "#tensor_sar = sar.ToTensor()\n",
    "    #transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    #transforms.unsqeueeze(0)\n",
    "\n",
    "# Convert SAR data to PyTorch tensor\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "tensor_sar = transform(sar)\n",
    "\n",
    "## DEFINE THE CLASSIFICATION CLASSES ##\n",
    "\n",
    "\n",
    "# To fix the following error: \"URLError: <urlopen error [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: certificate has expired (_ssl.c:1129)>\" #\n",
    "import ssl\n",
    "ssl._create_default_https_context = ssl._create_unverified_context\n",
    "\n",
    "## DEFINE THE MODEL ##\n",
    "#class Model (pl.LightningModule):\n",
    "#    densenet = smp.Unet('densenet201', encoder_weights='imagenet', in_channels=3)\n",
    "#    # Replace Output of Fully Connected Layer with Number of Labels for our Classification Problem\n",
    "#    densenet.fc = Linear(in_features=512, out_features=2)\n",
    "#    # Optimiser\n",
    "#    # TEST BOTH - optimiser1 doesn't work\n",
    "#    # optimiser1 = Adam(densenet.parameters(), lr=3e-4, weight_decay=0.0001)\n",
    "#    optimizer = torch.optim.Adam(densenet.parameters(), lr=3e-4)\n",
    "#\n",
    "#    # Loss Function\n",
    "#    loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "### CORRECTED CLASS DEFINITION ###\n",
    "class Model(pl.LightningModule):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.densenet = smp.Unet('densenet201', encoder_weights='imagenet', in_channels=3)\n",
    "        # Replace output of Fully Connected Layer with number of labels for our classification problem\n",
    "        self.densenet.classifier = nn.Linear(in_features=512, out_features=2)\n",
    "        # Optimizer\n",
    "        self.optimizer = torch.optim.Adam(self.densenet.parameters(), lr=3e-4)\n",
    "        # Loss Function\n",
    "        self.loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Define how the input x should pass through the layers of the model\n",
    "        x = self.densenet(x)\n",
    "        return x\n",
    "\n",
    "    # TO FIX THE ERROR MisconfigurationException: No `training_step()` method defined. Lightning `Trainer` expects as minimum a `training_step()`, `train_dataloader()` and `configure_optimizers()` to be defined.\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        # Define what happens during one training step on one batch of data\n",
    "        x, y = batch\n",
    "        y_pred = self.forward(x)\n",
    "        loss = self.loss_fn(y_pred, y)\n",
    "        self.log('train_loss', loss)\n",
    "        return loss\n",
    "\n",
    "    # TO FIX THE ERROR MisconfigurationException: No `training_step()` method defined. Lightning `Trainer` expects as minimum a `training_step()`, `train_dataloader()` and `configure_optimizers()` to be defined.\n",
    "    def configure_optimizers(self):\n",
    "        # Return a list of optimizers and LR schedulers to use in training\n",
    "        return self.optimizer\n",
    "\n",
    "    # TO FIX THE ERROR MisconfigurationException: No `training_step()` method defined. Lightning `Trainer` expects as minimum a `training_step()`, `train_dataloader()` and `configure_optimizers()` to be defined.\n",
    "    def train_dataloader(self):\n",
    "        # Return a DataLoader object for the training data\n",
    "        # Replace with your own DataLoader object\n",
    "        return train_dataloader\n",
    "\n",
    "## TRAIN THE MODEL ##\n",
    "model = Model()\n",
    "\n",
    "# Instantiate a Trainer object and train the model\n",
    "trainer = Trainer(\n",
    "    gpus=0,\n",
    "    accelerator=\"cpu\", \n",
    "    max_epochs=10 \n",
    "    #callbacks=[early_stop_callback], \n",
    "    #progress_bar_refresh_rate=20\n",
    ")\n",
    "\n",
    "trainer.fit(model, tensor_sar)\n",
    "\n",
    "#model.fit(model, tensor_sar) \n",
    "\n",
    "## TEST THE MODEL ##\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## IMPORT THE MODULES ##\n",
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "import pytorch_lightning as pl\n",
    "import segmentation_models_pytorch as smp\n",
    "from skimage import io\n",
    "from torchvision import transforms\n",
    "import torch.nn as nn\n",
    "from pytorch_lightning import Trainer\n",
    "\n",
    "#### LOAD THE DATA : ATTEMPT 3 ###\n",
    "sar_name = \"/Users/meghanplumridge/Desktop/CNN_sar_data/lbls_WS_20181202T_00088_[10752,1280]_256x256.tiff\"\n",
    "chart_name = \"/Users/meghanplumridge/Desktop/CNN_chart_data/ftrs_WS_20181202T_00088_[10752,1280]_256x256.tiff\"\n",
    "\n",
    "\n",
    "sar = io.imread(sar_name).copy()  # take all bands for shape of 256 x 256 x 3\n",
    "chart = io.imread(chart_name).copy()[:, :, 0]  # take red band only for shape of 256 x 256 x 1\n",
    "chart[chart < 80] = 0  # binarise to water\n",
    "chart[chart >= 80] = 255  # binarise to ice\n",
    "\n",
    "## TRANSFORM THE DATA ##\n",
    "# Convert SAR data to PyTorch tensor\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "tensor_sar = transform(sar)\n",
    "\n",
    "# To fix the following error: \"URLError: <urlopen error [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: certificate has expired (_ssl.c:1129)>\" #\n",
    "import ssl\n",
    "ssl._create_default_https_context = ssl._create_unverified_context\n",
    "\n",
    "## DEFINE THE MODEL ##\n",
    "class Model(pl.LightningModule):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.densenet = smp.Unet('densenet201', encoder_weights='imagenet', in_channels=3)\n",
    "        # Replace output of Fully Connected Layer with number of labels for our classification problem\n",
    "        self.densenet.classifier = nn.Linear(in_features=512, out_features=2)\n",
    "        # Optimizer\n",
    "        self.optimizer = torch.optim.Adam(self.densenet.parameters(), lr=3e-4)\n",
    "        # Loss Function\n",
    "        self.loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Define how the input x should pass through the layers of the model\n",
    "        x = self.densenet(x)\n",
    "        return x\n",
    "\n",
    "    ### THE \"TOO MANY VALUES ERROR CONTINUED, even after updating train_dataloader.\"\n",
    "    # Define what happens during one training step on one batch of data\n",
    "    #def training_step(self, batch, batch_idx):\n",
    "    #    x, y = batch\n",
    "    #    y_pred = self.forward(x)\n",
    "    #    loss = self.loss_fn(y_pred, y)\n",
    "    #    self.log('train_loss', loss)\n",
    "    #    return loss\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "    # Define what happens during one training step on one batch of data\n",
    "        x, y, *_ = batch  # use * to unpack the remaining elements in batch if there are more than 2\n",
    "        y_pred = self.forward(x)\n",
    "        loss = self.loss_fn(y_pred, y)\n",
    "        self.log('train_loss', loss)\n",
    "        return loss\n",
    "\n",
    "    # Return a list of optimizers and LR schedulers to use in training\n",
    "    def configure_optimizers(self):\n",
    "        return self.optimizer\n",
    "\n",
    "    def train_dataloader(self):\n",
    "    # Replace with your own DataLoader object\n",
    "        # Updating train_data to a list of tuples where each tuple has the SAR tensor and the corresponding chart tensor\n",
    "        train_data = [(tensor_sar, chart.unsqueeze(0))]\n",
    "        train_loader = torch.utils.data.DataLoader(train_data, batch_size=1, shuffle=True)\n",
    "        for batch in train_loader:\n",
    "            yield batch[0], batch[1].unsqueeze(1).long()\n",
    "\n",
    "    ### THIS ALSO DID NOT WORK - ValueError: not enough values to unpack (expected 2, got 1) ###\n",
    "    #def train_dataloader(self):\n",
    "    ## Replace with your own DataLoader object\n",
    "    #    train_data = [(tensor_sar, chart)]\n",
    "    #    train_loader = torch.utils.data.DataLoader(train_data, batch_size=1, shuffle=True)\n",
    "    #    return train_loader\n",
    "    \n",
    "    ### THIS DID NOT WORK - ValueError: too many values to unpack (expected 2) ###\n",
    "    ## Return a DataLoader object for the training data\n",
    "    #def train_dataloader(self):\n",
    "    #    return torch.utils.data.DataLoader(tensor_sar, batch_size=1)\n",
    "\n",
    "## TRAIN THE MODEL ##\n",
    "model = Model()\n",
    "\n",
    "# Instantiate a Trainer object and train the model\n",
    "trainer = Trainer(\n",
    "    gpus=0,\n",
    "    accelerator=\"cpu\", \n",
    "    max_epochs=10 \n",
    "    #callbacks=[early_stop_callback],\n",
    "    )\n",
    "\n",
    "trainer.fit(model, tensor_sar)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.utils.data as data_utils\n",
    "\n",
    "# define the training data\n",
    "train_sar = tensor_sar.unsqueeze(0)  # add a batch dimension to tensor_sar\n",
    "train_chart = chart.unsqueeze(0)  # add a batch dimension to chart\n",
    "train_data = data_utils.TensorDataset(train_sar, train_chart)\n",
    "\n",
    "# define the data loader\n",
    "train_loader = torch.utils.data.DataLoader(train_data, batch_size=1, shuffle=True)\n",
    "\n",
    "# update train_dataloader method\n",
    "def train_dataloader(self):\n",
    "    return train_loader\n",
    "\n",
    "# update training_step method\n",
    "def training_step(self, batch, batch_idx):\n",
    "    x, y = batch\n",
    "    y_pred = self.forward(x)\n",
    "    loss = self.loss_fn(y_pred, y.squeeze(1).long())\n",
    "    self.log('train_loss', loss)\n",
    "    return loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name     | Type             | Params\n",
      "----------------------------------------------\n",
      "0 | densenet | Unet             | 28.6 M\n",
      "1 | loss_fn  | CrossEntropyLoss | 0     \n",
      "----------------------------------------------\n",
      "28.6 M    Trainable params\n",
      "0         Non-trainable params\n",
      "28.6 M    Total params\n",
      "114.326   Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0:   0%|          | 0/1 [15:41<?, ?it/s].98s/it, loss=0, v_num=11]\n",
      "Epoch 0:   0%|          | 0/1 [15:23<?, ?it/s]\n",
      "Epoch 0:   0%|          | 0/1 [12:03<?, ?it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=10` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 1/1 [00:03<00:00,  3.53s/it, loss=0, v_num=11]\n"
     ]
    }
   ],
   "source": [
    "## IMPORT THE MODULES ##\n",
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "import pytorch_lightning as pl\n",
    "import segmentation_models_pytorch as smp\n",
    "from skimage import io\n",
    "from torchvision import transforms\n",
    "import torch.nn as nn\n",
    "from pytorch_lightning import Trainer\n",
    "import torch.utils.data as data_utils\n",
    "\n",
    "\n",
    "#### LOAD THE DATA : ATTEMPT 3 ###\n",
    "sar_name = \"/Users/meghanplumridge/Desktop/CNN_sar_data/lbls_WS_20181202T_00088_[10752,1280]_256x256.tiff\"\n",
    "chart_name = \"/Users/meghanplumridge/Desktop/CNN_chart_data/ftrs_WS_20181202T_00088_[10752,1280]_256x256.tiff\"\n",
    "\n",
    "\n",
    "### THIS CODE FAILS WITH ERROR RuntimeError: Given groups=1, weight of size [64, 3, 7, 7], expected input[1, 1, 256, 256] to have 3 channels, but got 1 channels instead #\n",
    "#sar = io.imread(sar_name).copy()  # take all bands for shape of 256 x 256 x 3\n",
    "## To solve the error: RuntimeError: Given groups=1, weight of size [64, 3, 7, 7], expected input[1, 1, 256, 256] to have 3 channels, but got 1 channels instead #\n",
    "## This code checks if the SAR data has only 1 channel and, if so, replicates the single channel 3 times to make it have 3 channels. This should ensure that the input to the model has the correct number of channels.\n",
    "#if sar.shape[-1] == 1:\n",
    "#    sar = np.repeat(sar, 3, axis=-1)\n",
    "#chart = io.imread(chart_name).copy()[:, :, 0]  # take red band only for shape of 256 x 256 x 1\n",
    "#chart[chart < 80] = 0  # binarise to water\n",
    "#chart[chart >= 80] = 255  # binarise to ice\n",
    "\n",
    "### TRY AGAIN ###\n",
    "sar = io.imread(sar_name).copy()[:, :, np.newaxis]  # add a channel dimension for shape of 256 x 256 x 1\n",
    "sar = np.repeat(sar, 3, axis=2)  # repeat the same SAR data to create 3-channel image\n",
    "chart = io.imread(chart_name).copy()[:, :, 0]  # take red band only for shape of 256 x 256 x 1\n",
    "chart[chart < 80] = 0  # binarise to water\n",
    "chart[chart >= 80] = 255  # binarise to ice\n",
    "\n",
    "\n",
    "## TRANSFORM THE DATA ##\n",
    "# Convert SAR data to PyTorch tensor\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "tensor_sar = transform(sar)\n",
    "tensor_chart = transform(chart)\n",
    "\n",
    "# define the training data\n",
    "train_sar = tensor_sar.unsqueeze(0)  # add a batch dimension to tensor_sar\n",
    "train_chart = tensor_chart.unsqueeze(0)  # add a batch dimension to chart\n",
    "train_data = data_utils.TensorDataset(train_sar, train_chart)\n",
    "\n",
    "# define the data loader\n",
    "train_loader = torch.utils.data.DataLoader(train_data, batch_size=1, shuffle=True)\n",
    "\n",
    "# To fix the following error: \"URLError: <urlopen error [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: certificate has expired (_ssl.c:1129)>\" #\n",
    "import ssl\n",
    "ssl._create_default_https_context = ssl._create_unverified_context\n",
    "\n",
    "## DEFINE THE MODEL ##\n",
    "class Model(pl.LightningModule):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.densenet = smp.Unet('densenet201', encoder_weights='imagenet', in_channels=3)\n",
    "        # Replace output of Fully Connected Layer with number of labels for our classification problem\n",
    "        self.densenet.classifier = nn.Linear(in_features=512, out_features=2)\n",
    "        # Optimizer\n",
    "        self.optimizer = torch.optim.Adam(self.densenet.parameters(), lr=3e-4)\n",
    "        # Loss Function\n",
    "        self.loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Define how the input x should pass through the layers of the model\n",
    "        x = self.densenet(x)\n",
    "        return x\n",
    "\n",
    "    ### THE \"TOO MANY VALUES ERROR CONTINUED, even after updating train_dataloader.\"\n",
    "    # Define what happens during one training step on one batch of data\n",
    "    #def training_step(self, batch, batch_idx):\n",
    "    #    x, y = batch\n",
    "    #    y_pred = self.forward(x)\n",
    "    #    loss = self.loss_fn(y_pred, y)\n",
    "    #    self.log('train_loss', loss)\n",
    "    #    return loss\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "    # Define what happens during one training step on one batch of data\n",
    "        x, y = batch\n",
    "        y_pred = self.forward(x)\n",
    "        loss = self.loss_fn(y_pred, y.squeeze(1).long())\n",
    "        self.log('train_loss', loss)\n",
    "        return loss\n",
    "\n",
    "    # Return a list of optimizers and LR schedulers to use in training\n",
    "    def configure_optimizers(self):\n",
    "        return self.optimizer\n",
    "\n",
    "    def train_dataloader(self):\n",
    "    # Replace with your own DataLoader object\n",
    "        train_data = [(tensor_sar, tensor_chart)]\n",
    "        input_data = torch.stack([data[0] for data in train_data])\n",
    "        target_data = torch.stack([data[1] for data in train_data])\n",
    "        train_loader = torch.utils.data.DataLoader(list(zip(input_data, target_data)), batch_size=1, shuffle=True)\n",
    "        return train_loader\n",
    "    \n",
    "    ### THIS RETURNS ERROR ValueError: too many values to unpack (expected 2) ###\n",
    "    #def train_dataloader(self):\n",
    "    #    return train_loader\n",
    "\n",
    "    ### THIS ALSO DID NOT WORK - ValueError: not enough values to unpack (expected 2, got 1) ###\n",
    "    #def train_dataloader(self):\n",
    "    ## Replace with your own DataLoader object\n",
    "    #    train_data = [(tensor_sar, chart)]\n",
    "    #    train_loader = torch.utils.data.DataLoader(train_data, batch_size=1, shuffle=True)\n",
    "    #    return train_loader\n",
    "    \n",
    "    ### THIS DID NOT WORK - ValueError: too many values to unpack (expected 2) ###\n",
    "    ## Return a DataLoader object for the training data\n",
    "    #def train_dataloader(self):\n",
    "    #    return torch.utils.data.DataLoader(tensor_sar, batch_size=1)\n",
    "\n",
    "## TRAIN THE MODEL ##\n",
    "model = Model()\n",
    "\n",
    "# Instantiate a Trainer object and train the model\n",
    "trainer = Trainer(\n",
    "    gpus=0,\n",
    "    accelerator=\"cpu\", \n",
    "    max_epochs=10 \n",
    "    #callbacks=[early_stop_callback],\n",
    "    )\n",
    "\n",
    "trainer.fit(model, train_loader)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(256, 256)\n"
     ]
    }
   ],
   "source": [
    "print(sar.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "256\n"
     ]
    }
   ],
   "source": [
    "print(sar.shape[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OMG THIS WORKS\n",
    "DO NOT TOUCH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name     | Type             | Params\n",
      "----------------------------------------------\n",
      "0 | densenet | Unet             | 28.6 M\n",
      "1 | loss_fn  | CrossEntropyLoss | 0     \n",
      "----------------------------------------------\n",
      "28.6 M    Trainable params\n",
      "0         Non-trainable params\n",
      "28.6 M    Total params\n",
      "114.326   Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 1/1 [00:02<00:00,  2.69s/it, loss=0, v_num=12]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=10` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 1/1 [00:03<00:00,  3.92s/it, loss=0, v_num=12]\n"
     ]
    }
   ],
   "source": [
    "## IMPORT THE MODULES ##\n",
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "import pytorch_lightning as pl\n",
    "import segmentation_models_pytorch as smp\n",
    "from skimage import io\n",
    "from torchvision import transforms\n",
    "import torch.nn as nn\n",
    "from pytorch_lightning import Trainer\n",
    "import torch.utils.data as data_utils\n",
    "\n",
    "\n",
    "#### LOAD THE DATA : ATTEMPT 3 ###\n",
    "sar_name = \"/Users/meghanplumridge/Desktop/CNN_sar_data/lbls_WS_20181202T_00088_[10752,1280]_256x256.tiff\"\n",
    "chart_name = \"/Users/meghanplumridge/Desktop/CNN_chart_data/ftrs_WS_20181202T_00088_[10752,1280]_256x256.tiff\"\n",
    "\n",
    "\n",
    "### THIS CODE FAILS WITH ERROR RuntimeError: Given groups=1, weight of size [64, 3, 7, 7], expected input[1, 1, 256, 256] to have 3 channels, but got 1 channels instead #\n",
    "#sar = io.imread(sar_name).copy()  # take all bands for shape of 256 x 256 x 3\n",
    "## To solve the error: RuntimeError: Given groups=1, weight of size [64, 3, 7, 7], expected input[1, 1, 256, 256] to have 3 channels, but got 1 channels instead #\n",
    "## This code checks if the SAR data has only 1 channel and, if so, replicates the single channel 3 times to make it have 3 channels. This should ensure that the input to the model has the correct number of channels.\n",
    "#if sar.shape[-1] == 1:\n",
    "#    sar = np.repeat(sar, 3, axis=-1)\n",
    "#chart = io.imread(chart_name).copy()[:, :, 0]  # take red band only for shape of 256 x 256 x 1\n",
    "#chart[chart < 80] = 0  # binarise to water\n",
    "#chart[chart >= 80] = 255  # binarise to ice\n",
    "\n",
    "### TRY AGAIN ###\n",
    "sar = io.imread(sar_name).copy()[:, :, np.newaxis]  # add a channel dimension for shape of 256 x 256 x 1\n",
    "sar = np.repeat(sar, 3, axis=2)  # repeat the same SAR data to create 3-channel image\n",
    "chart = io.imread(chart_name).copy()[:, :, 0]  # take red band only for shape of 256 x 256 x 1\n",
    "chart[chart < 80] = 0  # binarise to water\n",
    "chart[chart >= 80] = 255  # binarise to ice\n",
    "\n",
    "\n",
    "## TRANSFORM THE DATA ##\n",
    "# Convert SAR data to PyTorch tensor\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "tensor_sar = transform(sar)\n",
    "tensor_chart = transform(chart)\n",
    "\n",
    "# define the training data\n",
    "train_sar = tensor_sar.unsqueeze(0)  # add a batch dimension to tensor_sar\n",
    "train_chart = tensor_chart.unsqueeze(0)  # add a batch dimension to chart\n",
    "train_data = data_utils.TensorDataset(train_sar, train_chart)\n",
    "\n",
    "# define the data loader\n",
    "train_loader = torch.utils.data.DataLoader(train_data, batch_size=1, shuffle=True)\n",
    "\n",
    "# To fix the following error: \"URLError: <urlopen error [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: certificate has expired (_ssl.c:1129)>\" #\n",
    "import ssl\n",
    "ssl._create_default_https_context = ssl._create_unverified_context\n",
    "\n",
    "## DEFINE THE MODEL ##\n",
    "class Model(pl.LightningModule):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.densenet = smp.Unet('densenet201', encoder_weights='imagenet', in_channels=3)\n",
    "        # Replace output of Fully Connected Layer with number of labels for our classification problem\n",
    "        self.densenet.classifier = nn.Linear(in_features=512, out_features=2)\n",
    "        # Optimizer\n",
    "        self.optimizer = torch.optim.Adam(self.densenet.parameters(), lr=3e-4)\n",
    "        # Loss Function\n",
    "        self.loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Define how the input x should pass through the layers of the model\n",
    "        x = self.densenet(x)\n",
    "        return x\n",
    "\n",
    "    ### THE \"TOO MANY VALUES ERROR CONTINUED, even after updating train_dataloader.\"\n",
    "    # Define what happens during one training step on one batch of data\n",
    "    #def training_step(self, batch, batch_idx):\n",
    "    #    x, y = batch\n",
    "    #    y_pred = self.forward(x)\n",
    "    #    loss = self.loss_fn(y_pred, y)\n",
    "    #    self.log('train_loss', loss)\n",
    "    #    return loss\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "    # Define what happens during one training step on one batch of data\n",
    "        x, y = batch\n",
    "        y_pred = self.forward(x)\n",
    "        loss = self.loss_fn(y_pred, y.squeeze(1).long())\n",
    "        self.log('train_loss', loss)\n",
    "        return loss\n",
    "\n",
    "    # Return a list of optimizers and LR schedulers to use in training\n",
    "    def configure_optimizers(self):\n",
    "        return self.optimizer\n",
    "\n",
    "    def train_dataloader(self):\n",
    "    # Replace with your own DataLoader object\n",
    "        train_data = [(tensor_sar, tensor_chart)]\n",
    "        input_data = torch.stack([data[0] for data in train_data])\n",
    "        target_data = torch.stack([data[1] for data in train_data])\n",
    "        train_loader = torch.utils.data.DataLoader(list(zip(input_data, target_data)), batch_size=1, shuffle=True)\n",
    "        return train_loader\n",
    "    \n",
    "    ### THIS RETURNS ERROR ValueError: too many values to unpack (expected 2) ###\n",
    "    #def train_dataloader(self):\n",
    "    #    return train_loader\n",
    "\n",
    "    ### THIS ALSO DID NOT WORK - ValueError: not enough values to unpack (expected 2, got 1) ###\n",
    "    #def train_dataloader(self):\n",
    "    ## Replace with your own DataLoader object\n",
    "    #    train_data = [(tensor_sar, chart)]\n",
    "    #    train_loader = torch.utils.data.DataLoader(train_data, batch_size=1, shuffle=True)\n",
    "    #    return train_loader\n",
    "    \n",
    "    ### THIS DID NOT WORK - ValueError: too many values to unpack (expected 2) ###\n",
    "    ## Return a DataLoader object for the training data\n",
    "    #def train_dataloader(self):\n",
    "    #    return torch.utils.data.DataLoader(tensor_sar, batch_size=1)\n",
    "\n",
    "## TRAIN THE MODEL ##\n",
    "model = Model()\n",
    "\n",
    "# Instantiate a Trainer object and train the model\n",
    "trainer = Trainer(\n",
    "    gpus=0,\n",
    "    accelerator=\"cpu\", \n",
    "    max_epochs=10 \n",
    "    #callbacks=[early_stop_callback],\n",
    "    )\n",
    "\n",
    "trainer.fit(model, train_loader)\n",
    "\n",
    "# Save the trained model to a file\n",
    "trainer.save_checkpoint(\"/Users/meghanplumridge/Desktop/checkpoint.ckpt\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# WORKING, BOTH TRAIN AND TEST\n",
    "DO NOT MODIFY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/meghanplumridge/miniconda3/lib/python3.9/site-packages/pytorch_lightning/trainer/connectors/accelerator_connector.py:474: LightningDeprecationWarning: Setting `Trainer(gpus=0)` is deprecated in v1.7 and will be removed in v2.0. Please use `Trainer(accelerator='gpu', devices=0)` instead.\n",
      "  rank_zero_deprecation(\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name     | Type             | Params\n",
      "----------------------------------------------\n",
      "0 | densenet | Unet             | 28.6 M\n",
      "1 | loss_fn  | CrossEntropyLoss | 0     \n",
      "----------------------------------------------\n",
      "28.6 M    Trainable params\n",
      "0         Non-trainable params\n",
      "28.6 M    Total params\n",
      "114.326   Total estimated model params size (MB)\n",
      "/Users/meghanplumridge/miniconda3/lib/python3.9/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:224: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n",
      "/Users/meghanplumridge/miniconda3/lib/python3.9/site-packages/pytorch_lightning/trainer/trainer.py:1609: PossibleUserWarning: The number of training batches (1) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0:   0%|          | 0/1 [53:16<?, ?it/s].88s/it, loss=0, v_num=13]\n",
      "Epoch 9: 100%|██████████| 1/1 [00:01<00:00,  1.22s/it, loss=0, v_num=13]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=10` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 1/1 [00:01<00:00,  1.86s/it, loss=0, v_num=13]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/meghanplumridge/miniconda3/lib/python3.9/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:224: PossibleUserWarning: The dataloader, test_dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing DataLoader 0: 100%|██████████| 1/1 [00:00<00:00,  2.77it/s]\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss                   0.0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'test_loss': 0.0}]"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## IMPORT THE MODULES ##\n",
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "import pytorch_lightning as pl\n",
    "import segmentation_models_pytorch as smp\n",
    "from skimage import io\n",
    "from torchvision import transforms\n",
    "import torch.nn as nn\n",
    "from pytorch_lightning import Trainer\n",
    "import torch.utils.data as data_utils\n",
    "\n",
    "####################################################################################\n",
    "\n",
    "#### LOAD THE TRAINING DATA : ATTEMPT 3 ###\n",
    "sar_name = \"/Users/meghanplumridge/Desktop/CNN_sar_data/lbls_WS_20181202T_00088_[10752,1280]_256x256.tiff\"\n",
    "chart_name = \"/Users/meghanplumridge/Desktop/CNN_chart_data/ftrs_WS_20181202T_00088_[10752,1280]_256x256.tiff\"\n",
    "\n",
    "\n",
    "### THIS CODE FAILS WITH ERROR RuntimeError: Given groups=1, weight of size [64, 3, 7, 7], expected input[1, 1, 256, 256] to have 3 channels, but got 1 channels instead #\n",
    "#sar = io.imread(sar_name).copy()  # take all bands for shape of 256 x 256 x 3\n",
    "## To solve the error: RuntimeError: Given groups=1, weight of size [64, 3, 7, 7], expected input[1, 1, 256, 256] to have 3 channels, but got 1 channels instead #\n",
    "## This code checks if the SAR data has only 1 channel and, if so, replicates the single channel 3 times to make it have 3 channels. This should ensure that the input to the model has the correct number of channels.\n",
    "#if sar.shape[-1] == 1:\n",
    "#    sar = np.repeat(sar, 3, axis=-1)\n",
    "#chart = io.imread(chart_name).copy()[:, :, 0]  # take red band only for shape of 256 x 256 x 1\n",
    "#chart[chart < 80] = 0  # binarise to water\n",
    "#chart[chart >= 80] = 255  # binarise to ice\n",
    "\n",
    "### TRY AGAIN ###\n",
    "sar = io.imread(sar_name).copy()[:, :, np.newaxis]  # add a channel dimension for shape of 256 x 256 x 1\n",
    "sar = np.repeat(sar, 3, axis=2)  # repeat the same SAR data to create 3-channel image\n",
    "chart = io.imread(chart_name).copy()[:, :, 0]  # take red band only for shape of 256 x 256 x 1\n",
    "chart[chart < 80] = 0  # binarise to water\n",
    "chart[chart >= 80] = 255  # binarise to ice\n",
    "\n",
    "\n",
    "## TRANSFORM THE DATA ##\n",
    "# Convert SAR data to PyTorch tensor\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "tensor_sar = transform(sar)\n",
    "tensor_chart = transform(chart)\n",
    "\n",
    "# define the training data\n",
    "train_sar = tensor_sar.unsqueeze(0)  # add a batch dimension to tensor_sar\n",
    "train_chart = tensor_chart.unsqueeze(0)  # add a batch dimension to chart\n",
    "train_data = data_utils.TensorDataset(train_sar, train_chart)\n",
    "\n",
    "# define the data loader\n",
    "train_loader = torch.utils.data.DataLoader(train_data, batch_size=1, shuffle=True)\n",
    "\n",
    "####################################################################################\n",
    "\n",
    "#### LOAD THE TEST DATA ####\n",
    "\n",
    "## LOAD THE TEST DATA ##\n",
    "test_sar_name = \"/Users/meghanplumridge/Desktop/CNN_sar_data/lbls_WS_20181202T_00088_[10752,1280]_256x256.tiff\"\n",
    "test_chart_name = \"/Users/meghanplumridge/Desktop/CNN_chart_data/ftrs_WS_20181202T_00088_[10752,1280]_256x256.tiff\"\n",
    "\n",
    "\n",
    "test_sar = io.imread(test_sar_name).copy()[:, :, np.newaxis]  # add a channel dimension for shape of 256 x 256 x 1\n",
    "test_sar = np.repeat(test_sar, 3, axis=2)  # repeat the same SAR data to create 3-channel image\n",
    "test_chart = io.imread(test_chart_name).copy()[:, :, 0]  # take red band only for shape of 256 x 256 x 1\n",
    "test_chart[test_chart < 80] = 0  # binarise to water\n",
    "test_chart[test_chart >= 80] = 255  # binarise to ice\n",
    "\n",
    "# Convert SAR data to PyTorch tensor\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "test_tensor_sar = transform(test_sar)\n",
    "test_tensor_chart = transform(test_chart)\n",
    "\n",
    "# define the test data\n",
    "test_sar = test_tensor_sar.unsqueeze(0)  # add a batch dimension to tensor_sar\n",
    "test_chart = test_tensor_chart.unsqueeze(0)  # add a batch dimension to chart\n",
    "test_data = data_utils.TensorDataset(test_sar, test_chart)\n",
    "\n",
    "# define the data loader\n",
    "test_loader = torch.utils.data.DataLoader(test_data, batch_size=1, shuffle=False)\n",
    "\n",
    "####################################################################################\n",
    "\n",
    "# To fix the following error: \"URLError: <urlopen error [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: certificate has expired (_ssl.c:1129)>\" #\n",
    "import ssl\n",
    "ssl._create_default_https_context = ssl._create_unverified_context\n",
    "\n",
    "## DEFINE THE MODEL ##\n",
    "class Model(pl.LightningModule):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.densenet = smp.Unet('densenet201', encoder_weights='imagenet', in_channels=3)\n",
    "        # Replace output of Fully Connected Layer with number of labels for our classification problem\n",
    "        self.densenet.classifier = nn.Linear(in_features=512, out_features=2)\n",
    "        # Optimizer\n",
    "        self.optimizer = torch.optim.Adam(self.densenet.parameters(), lr=3e-4)\n",
    "        # Loss Function\n",
    "        self.loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Define how the input x should pass through the layers of the model\n",
    "        x = self.densenet(x)\n",
    "        return x\n",
    "\n",
    "    ### THE \"TOO MANY VALUES ERROR CONTINUED, even after updating train_dataloader.\"\n",
    "    # Define what happens during one training step on one batch of data\n",
    "    #def training_step(self, batch, batch_idx):\n",
    "    #    x, y = batch\n",
    "    #    y_pred = self.forward(x)\n",
    "    #    loss = self.loss_fn(y_pred, y)\n",
    "    #    self.log('train_loss', loss)\n",
    "    #    return loss\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "    # Define what happens during one training step on one batch of data\n",
    "        x, y = batch\n",
    "        y_pred = self.forward(x)\n",
    "        loss = self.loss_fn(y_pred, y.squeeze(1).long())\n",
    "        self.log('train_loss', loss)\n",
    "        return loss\n",
    "\n",
    "    # Return a list of optimizers and LR schedulers to use in training\n",
    "    def configure_optimizers(self):\n",
    "        return self.optimizer\n",
    "\n",
    "    def train_dataloader(self):\n",
    "    # Replace with your own DataLoader object\n",
    "        train_data = [(tensor_sar, tensor_chart)]\n",
    "        input_data = torch.stack([data[0] for data in train_data])\n",
    "        target_data = torch.stack([data[1] for data in train_data])\n",
    "        train_loader = torch.utils.data.DataLoader(list(zip(input_data, target_data)), batch_size=1, shuffle=True)\n",
    "        return train_loader\n",
    "\n",
    "    def test_step(self, batch, batch_idx):\n",
    "        # Define what happens during one test step on one batch of data\n",
    "        x, y = batch\n",
    "        y_pred = self.forward(x)\n",
    "        loss = self.loss_fn(y_pred, y.squeeze(1).long())\n",
    "        self.log('test_loss', loss)\n",
    "        return loss\n",
    "\n",
    "    def test_dataloader(self):\n",
    "        # Replace with your own DataLoader object\n",
    "        return test_loader\n",
    "    \n",
    "    ### THIS RETURNS ERROR ValueError: too many values to unpack (expected 2) ###\n",
    "    #def train_dataloader(self):\n",
    "    #    return train_loader\n",
    "\n",
    "    ### THIS ALSO DID NOT WORK - ValueError: not enough values to unpack (expected 2, got 1) ###\n",
    "    #def train_dataloader(self):\n",
    "    ## Replace with your own DataLoader object\n",
    "    #    train_data = [(tensor_sar, chart)]\n",
    "    #    train_loader = torch.utils.data.DataLoader(train_data, batch_size=1, shuffle=True)\n",
    "    #    return train_loader\n",
    "    \n",
    "    ### THIS DID NOT WORK - ValueError: too many values to unpack (expected 2) ###\n",
    "    ## Return a DataLoader object for the training data\n",
    "    #def train_dataloader(self):\n",
    "    #    return torch.utils.data.DataLoader(tensor_sar, batch_size=1)\n",
    "\n",
    "## TRAIN THE MODEL ##\n",
    "model = Model()\n",
    "\n",
    "# Instantiate a Trainer object and train the model\n",
    "trainer = Trainer(\n",
    "    gpus=0,\n",
    "    accelerator=\"cpu\", \n",
    "    max_epochs=10 \n",
    "    #callbacks=[early_stop_callback],\n",
    "    )\n",
    "\n",
    "trainer.fit(model, train_loader)\n",
    "\n",
    "# Save the trained model to a file\n",
    "trainer.save_checkpoint(\"/Users/meghanplumridge/Desktop/checkpoint.ckpt\")\n",
    "\n",
    "# Run the model\n",
    "trainer.test(model, test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "ename": "MisconfigurationException",
     "evalue": "No `test_step()` method defined to run `Trainer.test`.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mMisconfigurationException\u001b[0m                 Traceback (most recent call last)",
      "\u001b[1;32m/Users/meghanplumridge/Desktop/CNN.ipynb Cell 36\u001b[0m in \u001b[0;36m<cell line: 30>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/meghanplumridge/Desktop/CNN.ipynb#Y101sZmlsZQ%3D%3D?line=25'>26</a>\u001b[0m \u001b[39m# define the data loader\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/meghanplumridge/Desktop/CNN.ipynb#Y101sZmlsZQ%3D%3D?line=26'>27</a>\u001b[0m test_loader \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mutils\u001b[39m.\u001b[39mdata\u001b[39m.\u001b[39mDataLoader(test_data, batch_size\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m, shuffle\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/meghanplumridge/Desktop/CNN.ipynb#Y101sZmlsZQ%3D%3D?line=29'>30</a>\u001b[0m trainer\u001b[39m.\u001b[39;49mtest(model, test_loader)\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.9/site-packages/pytorch_lightning/trainer/trainer.py:794\u001b[0m, in \u001b[0;36mTrainer.test\u001b[0;34m(self, model, dataloaders, ckpt_path, verbose, datamodule)\u001b[0m\n\u001b[1;32m    792\u001b[0m     model \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_maybe_unwrap_optimized(model)\n\u001b[1;32m    793\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstrategy\u001b[39m.\u001b[39m_lightning_module \u001b[39m=\u001b[39m model\n\u001b[0;32m--> 794\u001b[0m \u001b[39mreturn\u001b[39;00m call\u001b[39m.\u001b[39;49m_call_and_handle_interrupt(\n\u001b[1;32m    795\u001b[0m     \u001b[39mself\u001b[39;49m, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_test_impl, model, dataloaders, ckpt_path, verbose, datamodule\n\u001b[1;32m    796\u001b[0m )\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.9/site-packages/pytorch_lightning/trainer/call.py:38\u001b[0m, in \u001b[0;36m_call_and_handle_interrupt\u001b[0;34m(trainer, trainer_fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m     36\u001b[0m         \u001b[39mreturn\u001b[39;00m trainer\u001b[39m.\u001b[39mstrategy\u001b[39m.\u001b[39mlauncher\u001b[39m.\u001b[39mlaunch(trainer_fn, \u001b[39m*\u001b[39margs, trainer\u001b[39m=\u001b[39mtrainer, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m     37\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m---> 38\u001b[0m         \u001b[39mreturn\u001b[39;00m trainer_fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m     40\u001b[0m \u001b[39mexcept\u001b[39;00m _TunerExitException:\n\u001b[1;32m     41\u001b[0m     trainer\u001b[39m.\u001b[39m_call_teardown_hook()\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.9/site-packages/pytorch_lightning/trainer/trainer.py:842\u001b[0m, in \u001b[0;36mTrainer._test_impl\u001b[0;34m(self, model, dataloaders, ckpt_path, verbose, datamodule)\u001b[0m\n\u001b[1;32m    839\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_tested_ckpt_path \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mckpt_path  \u001b[39m# TODO: remove in v1.8\u001b[39;00m\n\u001b[1;32m    841\u001b[0m \u001b[39m# run test\u001b[39;00m\n\u001b[0;32m--> 842\u001b[0m results \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_run(model, ckpt_path\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mckpt_path)\n\u001b[1;32m    844\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstate\u001b[39m.\u001b[39mstopped\n\u001b[1;32m    845\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtesting \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.9/site-packages/pytorch_lightning/trainer/trainer.py:1038\u001b[0m, in \u001b[0;36mTrainer._run\u001b[0;34m(self, model, ckpt_path)\u001b[0m\n\u001b[1;32m   1035\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_callback_connector\u001b[39m.\u001b[39m_attach_model_callbacks()\n\u001b[1;32m   1036\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_callback_connector\u001b[39m.\u001b[39m_attach_model_logging_functions()\n\u001b[0;32m-> 1038\u001b[0m verify_loop_configurations(\u001b[39mself\u001b[39;49m)\n\u001b[1;32m   1040\u001b[0m \u001b[39m# hook\u001b[39;00m\n\u001b[1;32m   1041\u001b[0m log\u001b[39m.\u001b[39mdetail(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m: preparing data\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.9/site-packages/pytorch_lightning/trainer/configuration_validator.py:47\u001b[0m, in \u001b[0;36mverify_loop_configurations\u001b[0;34m(trainer)\u001b[0m\n\u001b[1;32m     45\u001b[0m     __verify_eval_loop_configuration(model, \u001b[39m\"\u001b[39m\u001b[39mval\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m     46\u001b[0m \u001b[39melif\u001b[39;00m trainer\u001b[39m.\u001b[39mstate\u001b[39m.\u001b[39mfn \u001b[39m==\u001b[39m TrainerFn\u001b[39m.\u001b[39mTESTING:\n\u001b[0;32m---> 47\u001b[0m     __verify_eval_loop_configuration(model, \u001b[39m\"\u001b[39;49m\u001b[39mtest\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n\u001b[1;32m     48\u001b[0m \u001b[39melif\u001b[39;00m trainer\u001b[39m.\u001b[39mstate\u001b[39m.\u001b[39mfn \u001b[39m==\u001b[39m TrainerFn\u001b[39m.\u001b[39mPREDICTING:\n\u001b[1;32m     49\u001b[0m     __verify_eval_loop_configuration(model, \u001b[39m\"\u001b[39m\u001b[39mpredict\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.9/site-packages/pytorch_lightning/trainer/configuration_validator.py:131\u001b[0m, in \u001b[0;36m__verify_eval_loop_configuration\u001b[0;34m(model, stage)\u001b[0m\n\u001b[1;32m    126\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    127\u001b[0m     \u001b[39m# -----------------------------------\u001b[39;00m\n\u001b[1;32m    128\u001b[0m     \u001b[39m# verify model has an eval_step\u001b[39;00m\n\u001b[1;32m    129\u001b[0m     \u001b[39m# -----------------------------------\u001b[39;00m\n\u001b[1;32m    130\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m has_step:\n\u001b[0;32m--> 131\u001b[0m         \u001b[39mraise\u001b[39;00m MisconfigurationException(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mNo `\u001b[39m\u001b[39m{\u001b[39;00mstep_name\u001b[39m}\u001b[39;00m\u001b[39m()` method defined to run `Trainer.\u001b[39m\u001b[39m{\u001b[39;00mtrainer_method\u001b[39m}\u001b[39;00m\u001b[39m`.\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "\u001b[0;31mMisconfigurationException\u001b[0m: No `test_step()` method defined to run `Trainer.test`."
     ]
    }
   ],
   "source": [
    "### RUN THE MODEL WITH TEST DATA ###\n",
    "\n",
    "## LOAD THE TEST DATA ##\n",
    "test_sar_name = \"/Users/meghanplumridge/Desktop/CNN_sar_data/lbls_WS_20181202T_00088_[10752,1280]_256x256.tiff\"\n",
    "test_chart_name = \"/Users/meghanplumridge/Desktop/CNN_chart_data/ftrs_WS_20181202T_00088_[10752,1280]_256x256.tiff\"\n",
    "\n",
    "\n",
    "test_sar = io.imread(test_sar_name).copy()[:, :, np.newaxis]  # add a channel dimension for shape of 256 x 256 x 1\n",
    "test_sar = np.repeat(test_sar, 3, axis=2)  # repeat the same SAR data to create 3-channel image\n",
    "test_chart = io.imread(test_chart_name).copy()[:, :, 0]  # take red band only for shape of 256 x 256 x 1\n",
    "test_chart[test_chart < 80] = 0  # binarise to water\n",
    "test_chart[test_chart >= 80] = 255  # binarise to ice\n",
    "\n",
    "# Convert SAR data to PyTorch tensor\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "test_tensor_sar = transform(test_sar)\n",
    "test_tensor_chart = transform(test_chart)\n",
    "\n",
    "# define the test data\n",
    "test_sar = test_tensor_sar.unsqueeze(0)  # add a batch dimension to tensor_sar\n",
    "test_chart = test_tensor_chart.unsqueeze(0)  # add a batch dimension to chart\n",
    "test_data = data_utils.TensorDataset(test_sar, test_chart)\n",
    "\n",
    "# define the data loader\n",
    "test_loader = torch.utils.data.DataLoader(test_data, batch_size=1, shuffle=False)\n",
    "\n",
    "\n",
    "trainer.test(model, test_loader)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Model' object has no attribute 'predict'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m/Users/meghanplumridge/Desktop/CNN.ipynb Cell 36\u001b[0m in \u001b[0;36m<cell line: 35>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/meghanplumridge/Desktop/CNN.ipynb#X66sZmlsZQ%3D%3D?line=33'>34</a>\u001b[0m predictions \u001b[39m=\u001b[39m []\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/meghanplumridge/Desktop/CNN.ipynb#X66sZmlsZQ%3D%3D?line=34'>35</a>\u001b[0m \u001b[39mfor\u001b[39;00m batch \u001b[39min\u001b[39;00m test_loader:\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/meghanplumridge/Desktop/CNN.ipynb#X66sZmlsZQ%3D%3D?line=35'>36</a>\u001b[0m     \u001b[39m# Make predictions on the test batch\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/meghanplumridge/Desktop/CNN.ipynb#X66sZmlsZQ%3D%3D?line=36'>37</a>\u001b[0m     pred \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39;49mpredict(batch)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/meghanplumridge/Desktop/CNN.ipynb#X66sZmlsZQ%3D%3D?line=37'>38</a>\u001b[0m     \u001b[39m# Append the predictions to the list of predictions\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/meghanplumridge/Desktop/CNN.ipynb#X66sZmlsZQ%3D%3D?line=38'>39</a>\u001b[0m     predictions\u001b[39m.\u001b[39mappend(pred)\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.9/site-packages/torch/nn/modules/module.py:1207\u001b[0m, in \u001b[0;36mModule.__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   1205\u001b[0m     \u001b[39mif\u001b[39;00m name \u001b[39min\u001b[39;00m modules:\n\u001b[1;32m   1206\u001b[0m         \u001b[39mreturn\u001b[39;00m modules[name]\n\u001b[0;32m-> 1207\u001b[0m \u001b[39mraise\u001b[39;00m \u001b[39mAttributeError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39m'\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m object has no attribute \u001b[39m\u001b[39m'\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(\n\u001b[1;32m   1208\u001b[0m     \u001b[39mtype\u001b[39m(\u001b[39mself\u001b[39m)\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m, name))\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'Model' object has no attribute 'predict'"
     ]
    }
   ],
   "source": [
    "### RUN THE MODEL WITH TEST DATA ###\n",
    "\n",
    "## LOAD THE TEST DATA ##\n",
    "test_sar_name = \"/Users/meghanplumridge/Desktop/CNN_sar_data/lbls_WS_20181202T_00088_[10752,1280]_256x256.tiff\"\n",
    "test_chart_name = \"/Users/meghanplumridge/Desktop/CNN_chart_data/ftrs_WS_20181202T_00088_[10752,1280]_256x256.tiff\"\n",
    "\n",
    "\n",
    "test_sar = io.imread(test_sar_name).copy()[:, :, np.newaxis]  # add a channel dimension for shape of 256 x 256 x 1\n",
    "test_sar = np.repeat(test_sar, 3, axis=2)  # repeat the same SAR data to create 3-channel image\n",
    "test_chart = io.imread(test_chart_name).copy()[:, :, 0]  # take red band only for shape of 256 x 256 x 1\n",
    "test_chart[test_chart < 80] = 0  # binarise to water\n",
    "test_chart[test_chart >= 80] = 255  # binarise to ice\n",
    "\n",
    "# Convert SAR data to PyTorch tensor\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "test_tensor_sar = transform(test_sar)\n",
    "test_tensor_chart = transform(test_chart)\n",
    "\n",
    "# define the test data\n",
    "test_sar = test_tensor_sar.unsqueeze(0)  # add a batch dimension to tensor_sar\n",
    "test_chart = test_tensor_chart.unsqueeze(0)  # add a batch dimension to chart\n",
    "test_data = data_utils.TensorDataset(test_sar, test_chart)\n",
    "\n",
    "# define the data loader\n",
    "test_loader = torch.utils.data.DataLoader(test_data, batch_size=1, shuffle=False)\n",
    "\n",
    "\n",
    "## LOAD THE TRAINED MODEL ##\n",
    "model = Model.load_from_checkpoint(\"/Users/meghanplumridge/Desktop/checkpoint.ckpt\")\n",
    "\n",
    "## RUN THE PREDICTIONS ##\n",
    "predictions = []\n",
    "for batch in test_loader:\n",
    "    # Make predictions on the test batch\n",
    "    pred = model.predict(batch)\n",
    "    # Append the predictions to the list of predictions\n",
    "    predictions.append(pred)\n",
    "\n",
    "# Convert the predictions to a numpy array\n",
    "predictions = np.concatenate(predictions, axis=0)\n",
    "\n",
    "# You can now use the predictions as desired\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "base"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
